# Overview - Question Answering 2002

[`Proceedings`](./proceedings.md), [`Data`](./data.md), [`Runs`](./runs.md), [`Participants`](./participants.md)

{==

The TREC question answering track is an effort to bring the benefits of large-scale evaluation to bear on the question answering problem. The track contained two tasks in TREC 2002, the main task and the list task. Both tasks required that the answer strings returned by the systems consist of nothing more or less than an answer in contrast to the text snippets containing an answer allowed in previous years. A new evaluation measure in the main task, the confidence-weighted score, tested a systemâ€™s ability to recognize when it has found a correct answer.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- E.M. Voorhees, National Institute of Standards and Technology 

:material-text-search: **Tasks:**

- `main`: Main Task 
- `list`: List Task 

:fontawesome-solid-globe: **Track Web Page:** [`https://trec.nist.gov/data/qamain.html`](https://trec.nist.gov/data/qamain.html) 

---

