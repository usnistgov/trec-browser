# Runs - Legal 2011 

#### HELclrAM 
[**`Participants`**](./participants.md#dioileh) | [**`Proceedings`**](./proceedings.md#heliod-at-trec-legal-2011-learning-to-rank-from-relevance-feedback-for-e-discovery) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/HELclrAM.pdf) 

- :material-rename: **Run ID:** HELclrAM 
- :fontawesome-solid-user-group: **Participant:** dioileh 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `cde60bf552d82a03e35b2b0f292eac61` 
- :material-text: **Run description:** Constant LToR reorder of expansion with 20 grams run Learning to rank using query expansion retrieval scores as features, constant method reorder top 10,000 expand at [15,20,25,30] 

---
#### HELq20rAM 
[**`Participants`**](./participants.md#dioileh) | [**`Proceedings`**](./proceedings.md#heliod-at-trec-legal-2011-learning-to-rank-from-relevance-feedback-for-e-discovery) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/HELq20rAM.pdf) 

- :material-rename: **Run ID:** HELq20rAM 
- :fontawesome-solid-user-group: **Participant:** dioileh 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `02af151ed96761d56acaa4c24f3a4397` 
- :material-text: **Run description:** Expansion with 20 terms based on TF Language model using queries expanded with top 20 terms. 

---
#### HELqlaA1 
[**`Participants`**](./participants.md#dioileh) | [**`Proceedings`**](./proceedings.md#heliod-at-trec-legal-2011-learning-to-rank-from-relevance-feedback-for-e-discovery) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/HELqlaA1.pdf) 

- :material-rename: **Run ID:** HELqlaA1 
- :fontawesome-solid-user-group: **Participant:** dioileh 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `a368122b2b5298d82a0caa513c9f8889` 
- :material-text: **Run description:** Previous retrieved max 5000 documents, this run retrieves max all documents. Dirichlet language model for query and all emails 

---
#### ISICLST1 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISICLST1.pdf) 

- :material-rename: **Run ID:** ISICLST1 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/10/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `e2baf78555abc22ee02d09af3af4acaf` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. probability = 1/rank 

---
#### ISICLUT1 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISICLUT1.pdf) 

- :material-rename: **Run ID:** ISICLUT1 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/9/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `eb18dfcbc12314de7e46b4ee0bea2171` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. probability = 1/rank 

---
#### ISICLUT2 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISICLUT2.pdf) 

- :material-rename: **Run ID:** ISICLUT2 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/19/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `252da99c4ef3e11277a0ea8bb6552311` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was judged responsive by TA, was chosen as a responsive cluster. probability = 1/rank 

---
#### ISIFUSAM 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISIFUSAM.pdf) 

- :material-rename: **Run ID:** ISIFUSAM 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `ca4451fc370761827696d51ed178862c` 
- :material-text: **Run description:** We produced two runs - one, by Terrier 3.0 Relevance Feedback and the other, by ranking the judged relevant documents above the other documents in the collection. Then, we fused these two runs using Z-fusion technique to produce this run. probability = 1/rank 

---
#### ISIFuSAM 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISIFuSAM.pdf) 

- :material-rename: **Run ID:** ISIFuSAM 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b9eba89df27db62329219dc1a89fbead` 
- :material-text: **Run description:** We produced two runs - one, by Terrier 3.0 Relevance Feedback and the other, by ranking the judged relevant documents above the other documents in the collection. Then, we fused these two runs using Z-fusion technique to produce this run. probability = 1/rank 

---
#### ISILrFTF 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISILrFTF.pdf) 

- :material-rename: **Run ID:** ISILrFTF 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `1829de05713f1829e8172def61b25ee6` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. Based on the judged relevant documents, we performed Relevance Feedback using Terrier 3.0. The Indri query was then expanded using the feedback from Terrier. probability = 1/rank 

---
#### ISILRFTF 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISILRFTF.pdf) 

- :material-rename: **Run ID:** ISILRFTF 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `4cbf6a63d1f657c04fdba0230d49fc1f` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. Based on the judged relevant documents, we performed Relevance Feedback using Terrier 3.0. The Indri query was then expanded using the feedback from Terrier. probability = 1/rank 

---
#### ISIRFCT2 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISIRFCT2.pdf) 

- :material-rename: **Run ID:** ISIRFCT2 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/25/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `545b10179ea567d27c64f4d58f94f428` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. Based on the judged relevant documents, we performed Relevance Feedback.  probability = 1/rank 

---
#### ISIRoTAM 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISIRoTAM.pdf) 

- :material-rename: **Run ID:** ISIRoTAM 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `611c2fbe0a11309253181ec5a73f52a1` 
- :material-text: **Run description:**  The judged relevant documents in the mop-up collection are ranked arbitrarily. Then, the remaining documents in the collection were placed arbitrarily in the run after the judged relevant documents. probability = 1/rank 

---
#### ISIROTAM 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISIROTAM.pdf) 

- :material-rename: **Run ID:** ISIROTAM 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `835fc225d2279334c6e4e8c401a84632` 
- :material-text: **Run description:** The judged relevant documents in the mop-up collection are ranked arbitrarily. Then, the remaining documents in the collection were placed arbitrarily in the run after the judged relevant documents. probability = 1/rank 

---
#### ISIROTTF 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISIROTTF.pdf) 

- :material-rename: **Run ID:** ISIROTTF 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `6183b947f49dda67c3af83e35a0cdb12` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. Based on the judged relevant documents, we performed Relevance Feedback using Terrier 3.0 and Indri. probability = 1/rank 

---
#### ISIRoTTF 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISIRoTTF.pdf) 

- :material-rename: **Run ID:** ISIRoTTF 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `f3b02ed8f41ae109d4dd48e99cd6a0ba` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. Based on the judged relevant documents, we performed Relevance Feedback using Terrier 3.0 and Indri. probability = 1/rank 

---
#### ISITrFAM 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISITrFAM.pdf) 

- :material-rename: **Run ID:** ISITrFAM 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `f4e94e1ff076fbdfcb9e196bbbb72513` 
- :material-text: **Run description:** Based on the judged relevant documents in the mop-up documents, we performed Relevance Feedback using Terrier 3.0. probability = 1/rank 

---
#### ISITRFAM 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISITRFAM.pdf) 

- :material-rename: **Run ID:** ISITRFAM 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `8047934338255773fdd50f367464ef85` 
- :material-text: **Run description:** Based on the judged relevant documents in the mop-up documents, we performed Relevance Feedback using Terrier 3.0. probability = 1/rank 

---
#### ISITRFTF 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISITRFTF.pdf) 

- :material-rename: **Run ID:** ISITRFTF 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `767bf745d6b13e16e176e0b19ec97698` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. Based on the judged relevant documents, we performed Relevance Feedback using Terrier 3.0. probability = 1/rank 

---
#### ISITrFTF 
[**`Participants`**](./participants.md#irisical) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/ISITrFTF.pdf) 

- :material-rename: **Run ID:** ISITrFTF 
- :fontawesome-solid-user-group: **Participant:** IRISICAL 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `59989daad0e33d6b95b969c7833814ab` 
- :material-text: **Run description:** The notion of relevance was imbibed from the kickoff call. Next documents were retrieved using Indri. These documents were clustered. One, arbitrarily chosen document from each cluster was reviewed for responsiveness. The cluster whose representative was deemed responsive, was chosen as a responsive cluster. Based on the judged relevant documents, we performed Relevance Feedback using Terrier 3.0. probability = 1/rank 

---
#### mlbclsA1 
[**`Participants`**](./participants.md#unimelb_plus) | [**`Proceedings`**](./proceedings.md#melboune-at-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/mlbclsA1.pdf) 

- :material-rename: **Run ID:** mlbclsA1 
- :fontawesome-solid-user-group: **Participant:** unimelb_plus 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/10/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `d7c9cfe496ffc32ec2f9b07807878045` 
- :material-text: **Run description:** For initial interim run, just TF*IDF ranking based on topic keywords. Arbitrary values to force correct ranking. 

---
#### mlbclsAF 
[**`Participants`**](./participants.md#unimelb_plus) | [**`Proceedings`**](./proceedings.md#melboune-at-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/mlbclsAF.pdf) 

- :material-rename: **Run ID:** mlbclsAF 
- :fontawesome-solid-user-group: **Participant:** unimelb_plus 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `a424a7ec05d0b76fce54fa19c288e832` 
- :material-text: **Run description:** Please see above. SVM Platt method for learning prediction score to probability mapping function from cross-validated instances. 

---
#### mlblrnTF 
[**`Participants`**](./participants.md#unimelb_plus) | [**`Proceedings`**](./proceedings.md#melboune-at-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/mlblrnTF.pdf) 

- :material-rename: **Run ID:** mlblrnTF 
- :fontawesome-solid-user-group: **Participant:** unimelb_plus 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `ad5a356ac121b5db69ee02f23a981e08` 
- :material-text: **Run description:** Please see above. SVM Platt method for learning prediction score to probability mapping function from cross-validated instances. 

---
#### mlblrnTM 
[**`Participants`**](./participants.md#unimelb_plus) | [**`Proceedings`**](./proceedings.md#melboune-at-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/mlblrnTM.pdf) 

- :material-rename: **Run ID:** mlblrnTM 
- :fontawesome-solid-user-group: **Participant:** unimelb_plus 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `c89cf3bd43f3f6f0d28cd6b022c4b220` 
- :material-text: **Run description:** Text-based SVM on mop-up labels. SVM Platt method to map classifier predictions to probabilities, based on cross-validation results on seed documents. 

---
#### otL11BT1 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11BT1.pdf) 

- :material-rename: **Run ID:** otL11BT1 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/1/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b16e000aa6529adb969eca71a6e5dc07` 
- :material-text: **Run description:** Boolean-based run. For Boolean matches, the probability formula was the same as last year, i.e. take the raw rsv score (usually between 0 and 500), multiply by 0.002, square it, divide by 0.75, and enforce a max of 0.75 and min of 0.0001.  Non-matches were all assigned the min of 0.0001. 

---
#### otL11BT2 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11BT2.pdf) 

- :material-rename: **Run ID:** otL11BT2 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `86bacaafc4e17d7576b21da1399be2df` 
- :material-text: **Run description:** Boolean-based run for which the prob estimates were improved using the 100 example judgments per topic. Same as otL11FT2 except that the exponents were 3.14, 1.61 and 8.54 for the 3 topics respectively. 

---
#### otL11BTM 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11BTM.pdf) 

- :material-rename: **Run ID:** otL11BTM 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/5/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `ab76b790766537233075fbeffcc6957c` 
- :material-text: **Run description:** Boolean-based run with mopup rels moved to front and for which the prob estimates were improved using an earlier sample of 100 example judgments per topic. Same as otL11FTM except that the exponents were 3.86, 1.83 and 9.07 for the 3 topics respectively. 

---
#### otL11FT1 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11FT1.pdf) 

- :material-rename: **Run ID:** otL11FT1 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/26/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `73e6b6bd9512c8465dd3faf7b7d831c7` 
- :material-text: **Run description:** This run just used the terms in the topic statement. The probability formula was the same as last year, i.e. take the raw rsv score (usually between 0 and 500), multiply by 0.002, square it, divide by 0.75, and enforce a max of 0.75 and min of 0.0001.  Non-matches were all assigned the min of 0.0001. 

---
#### otL11FT2 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11FT2.pdf) 

- :material-rename: **Run ID:** otL11FT2 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/27/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `5374e087bceec31cbc5abeb039281f37` 
- :material-text: **Run description:** Pure relevance feedback run based on 100 example judgments per topic (no use of topic statements). The probability formula was to take the raw rsv score (usually between 0 and 500), multiply by 0.002, apply the exponent x, divide by 0.98, and enforce a max of 0.98 and min of 0.0001.  The known relevant documents were moved to the front and assigned 0.99, while the known non-relevant documents were assigned 0.01.  Exponent x was 2.237, 3.339, 3.301 for the 3 topics respectively, chosen to make the probs sum to the estimated number of relevant documents based on our sample of 100 docs per topic. 

---
#### otL11FTM 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11FTM.pdf) 

- :material-rename: **Run ID:** otL11FTM 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/5/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `24d368f5baee2fcb06834ed23ee3e083` 
- :material-text: **Run description:** Pure relevance feedback run based on the 2000+ example mopup judgments per topic (no use of topic statements). The probability formula was to take the raw rsv score (usually between 0 and 500), multiply by 0.002, apply the exponent x, divide by 0.98, and enforce a max of 0.98 and min of 0.0001.  The known relevant documents were moved to the front and assigned 0.99, while the known non-relevant documents were assigned 0.01.  Exponent x was 2.72, 3.92, 3.48 for the 3 topics respectively, chosen to make the probs sum to the estimated number of relevant documents based on our earlier sample of 100 docs per topic. 

---
#### otL11HT1 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11HT1.pdf) 

- :material-rename: **Run ID:** otL11HT1 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `60d71319c84cf1f0820ef403d3460782` 
- :material-text: **Run description:** Fusion run of otL11BT1 and otL11FT1. The probability of a doc is just the arithmetic mean of the probabilities of that doc in the otL11BT1 and otL11FT1 runs. 

---
#### otL11HT2 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11HT2.pdf) 

- :material-rename: **Run ID:** otL11HT2 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `ace8794f9dde78ca4a0cd3037358cdfb` 
- :material-text: **Run description:** Fusion run of otL11BT2 and otL11FT2. The probability of a doc is just the arithmetic mean of the probabilities of that doc in the otL11BT2 and otL11FT2 runs. 

---
#### otL11HTM 
[**`Participants`**](./participants.md#ot) | [**`Proceedings`**](./proceedings.md#learning-task-experiments-in-the-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/otL11HTM.pdf) 

- :material-rename: **Run ID:** otL11HTM 
- :fontawesome-solid-user-group: **Participant:** ot 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/5/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `d9b6c49aef885f9571b2c101ed07afe3` 
- :material-text: **Run description:** Fusion run of otL11BTM and otL11FTM. The probability of a doc is just the arithmetic mean of the probabilities of that doc in the otL11BTM and otL11FTM runs. 

---
#### priindA1 
[**`Participants`**](./participants.md#pris) | [**`Proceedings`**](./proceedings.md#pris-at-trec-2011-legal-track-discovery-based-on-relevant-feedback) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/priindA1.pdf) 

- :material-rename: **Run ID:** priindA1 
- :fontawesome-solid-user-group: **Participant:** PRIS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 7/19/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `f5e541c25ae65b0467e00f4bf67533c8` 
- :material-text: **Run description:** we use indri as the searching tool  we use tf and idf as the feature  we use edit distance as the similarity function  tf and idf is used as the feature edit distance is used as the similarity function  

---
#### priindA2 
[**`Participants`**](./participants.md#pris) | [**`Proceedings`**](./proceedings.md#pris-at-trec-2011-legal-track-discovery-based-on-relevant-feedback) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/priindA2.pdf) 

- :material-rename: **Run ID:** priindA2 
- :fontawesome-solid-user-group: **Participant:** PRIS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/16/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `51aea2a80d82fe7780912a6a403f4cd6` 
- :material-text: **Run description:** we use the feedback judgements as our training data  we use a bayes based algorithm to give every candidate document a probability we sort the probability as our final result we use a bayes based algorithm 

---
#### priindA3 
[**`Participants`**](./participants.md#bupt_wildcat) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/priindA3.pdf) 

- :material-rename: **Run ID:** priindA3 
- :fontawesome-solid-user-group: **Participant:** BUPT_WILDCAT 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `a7dd59096cbd8e34b2f834afa504b8b3` 
- :material-text: **Run description:** feedback and indri we combine the score of indri and the probabilities of the feature of the file 

---
#### priindAM 
[**`Participants`**](./participants.md#bupt_wildcat) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/priindAM.pdf) 

- :material-rename: **Run ID:** priindAM 
- :fontawesome-solid-user-group: **Participant:** BUPT_WILDCAT 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/7/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `8382c66b97854506dc048453b61ffc64` 
- :material-text: **Run description:** feedback and indri we combine the score of indri and the probabilities of the feature of the file 

---
#### recommind03T 
[**`Participants`**](./participants.md#recommind) | [**`Proceedings`**](./proceedings.md#recommind-at-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/recommind03T.pdf) 

- :material-rename: **Run ID:** recommind03T 
- :fontawesome-solid-user-group: **Participant:** Recommind 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/31/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `7339aefc87bcf033c29fa92afb3b69c0` 
- :material-text: **Run description:** A combination of Boolean searches, phrase extraction, conceptual analysis and random sampling was used to identify some potentially responsive documents.  These documents were then reviewed for responsiveness.  Documents found to be responsive were added to a seed set and trained on using proprietary machine learning techniques.  Documents returned form the training that had a high computer generated score were then passed on for human review.  The training and review process was then repeated Probabilities are derived using proprietary machine learning techniques and weighted with reviewer determinations 

---
#### recommind04T 
[**`Participants`**](./participants.md#recommind) | [**`Proceedings`**](./proceedings.md#recommind-at-trec-2011-legal-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/recommind04T.pdf) 

- :material-rename: **Run ID:** recommind04T 
- :fontawesome-solid-user-group: **Participant:** Recommind 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/7/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `de9bdb90d57673439fd13b25384c4b95` 
- :material-text: **Run description:** A combination of Boolean searches, phrase extraction, conceptual analysis and random sampling was used to identify some potentially responsive documents.  These documents were then reviewed for responsiveness.  Documents found to be responsive were added to a seed set and trained on using proprietary machine learning techniques.  Documents returned form the training that had a high computer generated score were then passed on for human review.  The training and review process was then repeated Probabilities are derived using proprietary machine learning techniques and weighted with reviewer determinations 

---
#### tcdicskwA1 
[**`Participants`**](./participants.md#tcdi) | [**`Proceedings`**](./proceedings.md#auto-relevancy-and-responsiveness-baseline-ii-improving-concept-search-to-establish-a-subset-with-maximized-recall-for-automated-first-pass-and-early-assessment-using-latent-semantic-indexing-lsi-bigrams-and-wordnet-3-0-seeding) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/tcdicskwA1.pdf) 

- :material-rename: **Run ID:** tcdicskwA1 
- :fontawesome-solid-user-group: **Participant:** TCDI 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/22/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `0f3ba28215229d2c0ed5a8b82ec1bbfb` 
- :material-text: **Run description:** This is an automated baseline to see how effective an automatically derived concept search+keyword + WordNet + bigram is with no exemplar requirement compared with categorization methods which require exemplars. LSI and underlying linear features of WN and bigram. 

---
#### tcdihentA3 
[**`Participants`**](./participants.md#tcdi) | [**`Proceedings`**](./proceedings.md#auto-relevancy-and-responsiveness-baseline-ii-improving-concept-search-to-establish-a-subset-with-maximized-recall-for-automated-first-pass-and-early-assessment-using-latent-semantic-indexing-lsi-bigrams-and-wordnet-3-0-seeding) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/tcdihentA3.pdf) 

- :material-rename: **Run ID:** tcdihentA3 
- :fontawesome-solid-user-group: **Participant:** TCDI 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/29/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `ef04a45c5220de4d369cdfcd7e9ce832` 
- :material-text: **Run description:** Wordnet LSI bigram and 40 yes/no responsive calls from TA for each topic with emphasis on feature building Wordnet LSI bigram Bayes high entropy 

---
#### tcdilentA2 
[**`Participants`**](./participants.md#tcdi) | [**`Proceedings`**](./proceedings.md#auto-relevancy-and-responsiveness-baseline-ii-improving-concept-search-to-establish-a-subset-with-maximized-recall-for-automated-first-pass-and-early-assessment-using-latent-semantic-indexing-lsi-bigrams-and-wordnet-3-0-seeding) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/tcdilentA2.pdf) 

- :material-rename: **Run ID:** tcdilentA2 
- :fontawesome-solid-user-group: **Participant:** TCDI 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/29/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `7739aa797375236b5292a921d2a4e8ef` 
- :material-text: **Run description:** Wordnet LSI bigram and 40 yes/no responsive calls from TA for each topic with emphasis on feature building Wordnet LSI bigram Bayes 

---
#### tcdinokaAF 
[**`Participants`**](./participants.md#tcdi) | [**`Proceedings`**](./proceedings.md#auto-relevancy-and-responsiveness-baseline-ii-improving-concept-search-to-establish-a-subset-with-maximized-recall-for-automated-first-pass-and-early-assessment-using-latent-semantic-indexing-lsi-bigrams-and-wordnet-3-0-seeding) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/tcdinokaAF.pdf) 

- :material-rename: **Run ID:** tcdinokaAF 
- :fontawesome-solid-user-group: **Participant:** TCDI 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/30/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `00a5b3cbfe22a552d213308108cf1cc0` 
- :material-text: **Run description:** This run is the control, taking in no account of TA assessments (compare with runs 1-3).  Also, no keyword filter is applied as in 1-3.  So I expect this run to be high recall but low precision. LSI based on golden ratio. 

---
#### URS205A1 
[**`Participants`**](./participants.md#ursinus) | [**`Proceedings`**](./proceedings.md#latent-semantic-indexing-with-selective-query-expansion) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/URS205A1.pdf) 

- :material-rename: **Run ID:** URS205A1 
- :fontawesome-solid-user-group: **Participant:** URSINUS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/18/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `71d308516d37239528c70af6618dfd6c` 
- :material-text: **Run description:** Term frequency-inverse document frequency weighting on the term-document matrix. Then LSI with 205 singular values is applied with a .25 weight and Vector Space retrieval is applied with a .75 weight to get the final scores. This run differs from the future runs in that it does not use any query expansion, because we have no information about which documents are relevant. The documents are represented as vectors in a plane, along with the queries, based on the termdoc matrix. The cosine similarities are taken between each document. This results in a value between 0 and 1, which we use directly for the probability. 

---
#### URS205A3 
[**`Participants`**](./participants.md#ursinus) | [**`Proceedings`**](./proceedings.md#latent-semantic-indexing-with-selective-query-expansion) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/URS205A3.pdf) 

- :material-rename: **Run ID:** URS205A3 
- :fontawesome-solid-user-group: **Participant:** URSINUS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/29/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `2adc68d017147125b3c141736952ccb6` 
- :material-text: **Run description:** We used a combination of LSI and vector-space retrieval techniques (called Essential Dimensions of LSI (EDLSI)) combined with selective query expansion based on the determinations from the TAs. We used the cosine similarity of the query vector compared to each document to represent the probability. This is naturally a number between 0 and 1. 

---
#### URS205AM 
[**`Participants`**](./participants.md#ursinus) | [**`Proceedings`**](./proceedings.md#latent-semantic-indexing-with-selective-query-expansion) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/URS205AM.pdf) 

- :material-rename: **Run ID:** URS205AM 
- :fontawesome-solid-user-group: **Participant:** URSINUS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/7/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `f2671db12f28b6884ba26d117add0e97` 
- :material-text: **Run description:** This is the mopup run and uses all determination requests from all teams.  The documents are represented as vectors in a plane, along with the queries, based on the termdoc matrix. The cosine similarities are taken between each document. This results in a value between 0 and 1, which we use directly for the probability. 

---
#### URS222A2 
[**`Participants`**](./participants.md#ursinus) | [**`Proceedings`**](./proceedings.md#latent-semantic-indexing-with-selective-query-expansion) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/URS222A2.pdf) 

- :material-rename: **Run ID:** URS222A2 
- :fontawesome-solid-user-group: **Participant:** URSINUS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/24/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `bf6662af58b3de037e817226c1b4f4b8` 
- :material-text: **Run description:** Differs from first run by way of query expansion using the first set of determinations. This is the second of two runs but since I haven't received feedback on my first determination set for topic 403, it is not included. In order to get more determinations for 401 and 402, I need to send in interim submissions. The cosine similarity results in a value between 0 and 1 which is used as the probability. 

---
#### URS403A2 
[**`Participants`**](./participants.md#ursinus) | [**`Proceedings`**](./proceedings.md#latent-semantic-indexing-with-selective-query-expansion) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/URS403A2.pdf) 

- :material-rename: **Run ID:** URS403A2 
- :fontawesome-solid-user-group: **Participant:** URSINUS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/25/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `046b7134380cd10675e37fd31f720a44` 
- :material-text: **Run description:** This run is just topic 403, as a run with 401 and 402 after the first 100 determinations has already been sent in. This is EDLSI using a query vector made up of the average of document vectors of docs we know to be relevant from the first determination set. Probabilities were estimated using the cosine similarity between a query vector and each document. 

---
#### USFDSET 
[**`Participants`**](./participants.md#usf_isds) | [**`Proceedings`**](./proceedings.md#modeling-concept-and-context-to-improve-performance-in-ediscovery) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/USFDSET.pdf) 

- :material-rename: **Run ID:** USFDSET 
- :fontawesome-solid-user-group: **Participant:** USF_ISDS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `dd6ada00cad245066b61f965fe61d026` 
- :material-text: **Run description:** In this case we tuned our classifier based on the responses to our 100 documents submitted. We then evaluated the 27 documents from our submission that were judged non-responsive to set our Elimination Component operator. This operator is our new development for this year. Last year we focused on recall, this year our focus is on precision.  These were calculated based on the total number of terms and occurrences. The document with the highest raw score of occurrences was ranked number one. Each document received a corresponding descending score for each lesser total occurrence of term scores after accounting for weighting coefficients. The least relevant documents which returned zero occurrences were ranked at the bottom of the list in a random order, given that they all are equally expected to be non-relevant.  

---
#### USFEOLT 
[**`Participants`**](./participants.md#usf_isds) | [**`Proceedings`**](./proceedings.md#modeling-concept-and-context-to-improve-performance-in-ediscovery) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/USFEOLT.pdf) 

- :material-rename: **Run ID:** USFEOLT 
- :fontawesome-solid-user-group: **Participant:** USF_ISDS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/22/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `c322eb42f29d88cd91c0eac1760d31b2` 
- :material-text: **Run description:** Context based search terms with filtering characteristics with a focus on the EOL search term The probabilites were based on context key word occurances of 3 random samples.  These were used to develop multipliers for the final probabilities and rankings 

---
#### USFMOPT 
[**`Participants`**](./participants.md#usf_isds) | [**`Proceedings`**](./proceedings.md#modeling-concept-and-context-to-improve-performance-in-ediscovery) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/USFMOPT.pdf) 

- :material-rename: **Run ID:** USFMOPT 
- :fontawesome-solid-user-group: **Participant:** USF_ISDS 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/4/2011 
- :fontawesome-solid-user-gear: **Type:** techassist 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `be3c672f1635e7b71dc748b951416fd4` 
- :material-text: **Run description:** In this case we tuned our classifier based on the responses to our 100 documents submitted. We then evaluated the 27 documents from our submission that were judged non-responsive to set our Elimination Component operator. This operator is our new development for this year. Last year we focused on recall, this year our focus is on precision.  These were calculated based on the total number of terms and occurrences. The document with the highest raw score of occurrences was ranked number one. Each document received a corresponding descending score for each lesser total occurrence of term scores after accounting for weighting coefficients. The least relevant documents which returned zero occurrences were ranked at the bottom of the list in a random order, given that they all are equally expected to be non-relevant.  For this mop up run we added a co-occurrence scoring method for low relevant terms occurring with high relevant documents. This allowed for us to push the co-occurrence documents higher in priority without raising the level of potentially non-relevant documents containing the lower level terms alone.   

---
#### UWABASA1 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWABASA1.pdf) 

- :material-rename: **Run ID:** UWABASA1 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/23/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `edf75bf0546cf6b66eb1ffbe62ead3d8` 
- :material-text: **Run description:** Base run with Okapi to measure increase in performance. Probability derived from okapi retrieval scores. 

---
#### UWABASA2 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWABASA2.pdf) 

- :material-rename: **Run ID:** UWABASA2 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b1f988a9c31c3192c6c9810c24e9c9ba` 
- :material-text: **Run description:** Okapi relevance feedback using first round TA determinations from TOP-100 document from pseudo relevance feedback. Derived from OKAPI scores. 

---
#### UWABASA3 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWABASA3.pdf) 

- :material-rename: **Run ID:** UWABASA3 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `d5c2ead23bc1dc8597760f428d51bc27` 
- :material-text: **Run description:** Okapi relevance feedback using first and second round TA determinations from TOP-200 document from pseudo relevance feedback. Derived from OKAPI scores. 

---
#### UWABASA4 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWABASA4.pdf) 

- :material-rename: **Run ID:** UWABASA4 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `579a5a4e422661d1dd9aff538e79767c` 
- :material-text: **Run description:** Okapi relevance feedback using first, second and third round TA determinations from TOP-300 document from pseudo relevance feedback. Derived from OKAPI scores. 

---
#### UWABASAF 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWABASAF.pdf) 

- :material-rename: **Run ID:** UWABASAF 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `8154d148780c2868edfec32da0ce66ee` 
- :material-text: **Run description:** Clone of UWABASA4 for administrative reasons.  Okapi relevance feedback on first second and third round TA documents. Initial document probability is derived from okapi relevance scores. 

---
#### UWABASAM 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWABASAM.pdf) 

- :material-rename: **Run ID:** UWABASAM 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `dca738a8e78160280ea29898da616c5c` 
- :material-text: **Run description:** okapi relevance feedback on all TA relevance determinations. Document probability is derived from okapi relevance scores. 

---
#### UWALINA2 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWALINA2.pdf) 

- :material-rename: **Run ID:** UWALINA2 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `463908626ef35b928a0894080be861cd` 
- :material-text: **Run description:**  Linear regression classifier trained on first round TA documents and top-10 relevance pseudo relevance feedback from Okapi runs. Using a linear regression classifier. 

---
#### UWALINA3 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWALINA3.pdf) 

- :material-rename: **Run ID:** UWALINA3 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `24336c7d495b1f4e46f38929bf1de28f` 
- :material-text: **Run description:**  Linear regression classifier trained on first and second round TA documents and top-10 relevance pseudo relevance feedback from Okapi runs. Using a linear regression classifier. 

---
#### UWALINA4 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWALINA4.pdf) 

- :material-rename: **Run ID:** UWALINA4 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `cf7b595f7b5e35e8a0652ac78ff51d8e` 
- :material-text: **Run description:**  Linear regression classifier trained on first, second and third round TA documents and top-10 relevance pseudo relevance feedback from Okapi runs. Using a linear regression classifier. 

---
#### UWALINAF 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWALINAF.pdf) 

- :material-rename: **Run ID:** UWALINAF 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `f32886607d44b40ff6421d049b36bf4e` 
- :material-text: **Run description:** Clone of UWALINA4 for administrative reasons.  Linear regression classifier trained on first, second and third round TA documents and top-10 relevance pseudo relevance feedback from Okapi runs. Using a linear regression classifier. 

---
#### UWALINAM 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWALINAM.pdf) 

- :material-rename: **Run ID:** UWALINAM 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `4354a6e4ba57c2f96decde1b2835dd60` 
- :material-text: **Run description:** Linear regression classifier trained on all TA relevance determinations. Using a linear regression classifier. 

---
#### UWASNAA1 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWASNAA1.pdf) 

- :material-rename: **Run ID:** UWASNAA1 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `fc55c34b9bc86dfa43c1b4b43b1530a3` 
- :material-text: **Run description:** Okapi pseudo relevance feedback and using social network analysis of document sender and receiver. Documents without sender and receiver tags only get okapi probability assigned. Initial document probability is derived from okapi relevance scores as well as the probability that the sender's communication is relevant based on all of his/her communication. 

---
#### UWASNAA2 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWASNAA2.pdf) 

- :material-rename: **Run ID:** UWASNAA2 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `34fbfb57fba39c8fc974af0490ad46fe` 
- :material-text: **Run description:** Okapi relevance feedback on first round TA documents and social network analysis of document sender and receiver. Documents without sender and receiver tags only get okapi probability assigned. Initial document probability is derived from okapi relevance scores as well as the probability that the sender's communication is relevant based on all of his/her communication. 

---
#### UWASNAA3 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWASNAA3.pdf) 

- :material-rename: **Run ID:** UWASNAA3 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b16154ed11883f304180feef8f1cfe09` 
- :material-text: **Run description:** Okapi relevance feedback on first and second round TA documents and social network analysis of document sender and receiver. Documents without sender and receiver tags only get okapi probability assigned. Initial document probability is derived from okapi relevance scores as well as the probability that the sender's communication is relevant based on all of his/her communication. 

---
#### UWASNAA4 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWASNAA4.pdf) 

- :material-rename: **Run ID:** UWASNAA4 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `e08b9e6050ae8c70d329f5b3f8f4fcfc` 
- :material-text: **Run description:** Okapi relevance feedback on first second and third round TA documents and social network analysis of document sender and receiver. Documents without sender and receiver tags only get okapi probability assigned. Initial document probability is derived from okapi relevance scores as well as the probability that the sender's communication is relevant based on all of his/her communication. 

---
#### UWASNAAF 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWASNAAF.pdf) 

- :material-rename: **Run ID:** UWASNAAF 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 8/28/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `0c686f856419117a246f451f8a4e785e` 
- :material-text: **Run description:** Clone of UWASNAA4 for administrative reasons.  Okapi relevance feedback on first second and third round TA documents and social network analysis of document sender and receiver. Documents without sender and receiver tags only get okapi probability assigned. Initial document probability is derived from okapi relevance scores as well as the probability that the sender's communication is relevant based on all of his/her communication. 

---
#### UWASNAAM 
[**`Participants`**](./participants.md#waterloo) | [**`Proceedings`**](./proceedings.md#university-of-waterloo-at-trec-2011-a-social-networking-approach-to-the-legal-learning-track) | [**`Appendix`**](https://trec.nist.gov/pubs/trec20/appendices/legal/UWASNAAM.pdf) 

- :material-rename: **Run ID:** UWASNAAM 
- :fontawesome-solid-user-group: **Participant:** waterloo 
- :material-format-text: **Track:** Legal 
- :material-calendar: **Year:** 2011 
- :material-upload: **Submission:** 9/6/2011 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `0dc0ed7d3dc43f5a9340310411f29b97` 
- :material-text: **Run description:** okapi relevance feedback on all TA relevance determinations and social network analysis of document sender and receiver.  Initial document probability is derived from okapi relevance scores as well as the probability that the sender's communication is relevant based on all of his/her communications. 

---
