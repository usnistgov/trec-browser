# Runs - Contextual Suggestion 2013 

#### 1 
[**`Participants`**](./participants.md#pris), [**`Input`**](https://trec.nist.gov/results/trec22/context/1.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/1.pdf) 

- :material-rename: **Run ID:** 1 
- :fontawesome-solid-user-group: **Participant:** PRIS 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `8d342203b458085c2eece535d3e7b744` 
- :material-text: **Run description:** calculate the similarities with Tf-idf ,reduce the dimension using LSI model  

---
#### 2 
[**`Participants`**](./participants.md#pris), [**`Input`**](https://trec.nist.gov/results/trec22/context/2.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/2.pdf) 

- :material-rename: **Run ID:** 2 
- :fontawesome-solid-user-group: **Participant:** PRIS 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b276d5d3ce677c59fff5c2531e73aaa7` 
- :material-text: **Run description:** using LSI model with another Coefficient (80) 

---
#### baselineA 
[**`Participants`**](./participants.md#uwaterlooclac), [**`Input`**](https://trec.nist.gov/results/trec22/context/baselineA.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/baselineA.pdf) 

- :material-rename: **Run ID:** baselineA 
- :fontawesome-solid-user-group: **Participant:** UWaterlooCLAC 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b8969757523f47d9b53661b7f6828a17` 
- :material-text: **Run description:** Results from Google Places API pointing to the Open Web filtered by whether the attraction has a corresponding URL. 

---
#### baselineB 
[**`Participants`**](./participants.md#uwaterlooclac), [**`Input`**](https://trec.nist.gov/results/trec22/context/baselineB.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/baselineB.pdf) 

- :material-rename: **Run ID:** baselineB 
- :fontawesome-solid-user-group: **Participant:** UWaterlooCLAC 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12cs 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `58212ca9d3ea3b52f9fc57b9b431747b` 
- :material-text: **Run description:** Results from Google Places API pointing to the documents in the ClueWeb contextual suggestion subcollection filtered by whether the attraction has a corresponding DocID. 

---
#### BOW_V17 
[**`Participants`**](./participants.md#georgetownyang), [**`Proceedings`**](./proceedings.md#boosting-venue-page-rankings-for-contextual-retrieval-georgetown-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/BOW_V17.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/BOW_V17.pdf) 

- :material-rename: **Run ID:** BOW_V17 
- :fontawesome-solid-user-group: **Participant:** GeorgetownYang 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12b13 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `af6a68cfa8e1404ce1e83cfb7058f602` 
- :material-text: **Run description:** category 

---
#### BOW_V18 
[**`Participants`**](./participants.md#georgetownyang), [**`Proceedings`**](./proceedings.md#boosting-venue-page-rankings-for-contextual-retrieval-georgetown-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/BOW_V18.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/BOW_V18.pdf) 

- :material-rename: **Run ID:** BOW_V18 
- :fontawesome-solid-user-group: **Participant:** GeorgetownYang 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12b13 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `343f164a409c3761787da3d03c26b653` 
- :material-text: **Run description:** use sample's category do retrieval 

---
#### CIRG_IRDISCOA 
[**`Participants`**](./participants.md#cirg_irdisco), [**`Proceedings`**](./proceedings.md#cirgirdisco-at-trec-2013-contextual-suggestion-track-using-the-wikipedia-graph-structure-for-item-to-item-recommendation), [**`Input`**](https://trec.nist.gov/results/trec22/context/CIRG_IRDISCOA.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/CIRG_IRDISCOA.pdf) 

- :material-rename: **Run ID:** CIRG_IRDISCOA 
- :fontawesome-solid-user-group: **Participant:** CIRG_IRDISCO 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b59588dad68109760dbed93a8ed76a77` 
- :material-text: **Run description:** Our runs are based on an item-item based similarity metric that is normally used in collaborative filtering. However, unlike traditional collaborative filtering approaches we make use of Wikipedia category graph and Wikipedia article graph to compute similarity between places fetched from Google Places and WikiTravel. The descriptions of example suggestions given as part of user profiles are decomposed into n-grams and from within these n-grams we filter those which have a corresponding Wikipedia entry (i.e., a Wikipedia article); finally we determine an intersection between these n-grams and the Wikipedia article titles extracted from n-grams of returned places' descriptions (using Google Places API and Bing API). The computed intersections (precisely, Wikipedia articles) are then used to further extract Wikipedia categories until depth 2 and these categories are used in a score computation framework that indicates a measure of similarity between example suggestions and returned places. 

---
#### CIRG_IRDISCOB 
[**`Participants`**](./participants.md#cirg_irdisco), [**`Proceedings`**](./proceedings.md#cirgirdisco-at-trec-2013-contextual-suggestion-track-using-the-wikipedia-graph-structure-for-item-to-item-recommendation), [**`Input`**](https://trec.nist.gov/results/trec22/context/CIRG_IRDISCOB.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/CIRG_IRDISCOB.pdf) 

- :material-rename: **Run ID:** CIRG_IRDISCOB 
- :fontawesome-solid-user-group: **Participant:** CIRG_IRDISCO 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `69f41ee949d198c48341b265234eedc7` 
- :material-text: **Run description:** Our runs are based on an item-item based similarity metric that is normally used in collaborative filtering. However, unlike traditional collaborative filtering approaches we make use of Wikipedia category graph and Wikipedia article graph to compute similarity between places fetched from Google Places and WikiTravel. The descriptions of example suggestions given as part of user profiles are decomposed into n-grams and from within these n-grams we filter those which have a corresponding Wikipedia entry (i.e., a Wikipedia article); finally we determine an intersection between these n-grams and the Wikipedia article titles extracted from n-grams of returned places' descriptions (using Google Places API and Bing API). The computed intersections (precisely, Wikipedia articles) are then used to further extract Wikipedia categories until depth 2 and these categories are used in a score computation framework that indicates a measure of similarity between example suggestions and returned places. This particular run assigns a high priority score to locations fetched from Wikitravel. 

---
#### complexScore 
[**`Participants`**](./participants.md#ulugano), [**`Proceedings`**](./proceedings.md#university-of-lugano-at-the-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/complexScore.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/complexScore.pdf) 

- :material-rename: **Run ID:** complexScore 
- :fontawesome-solid-user-group: **Participant:** ULugano 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/22/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `84e59f37095598b8daab7b49c25eead2` 
- :material-text: **Run description:** Main source is Google Place. Descriptions are fetched from Open Web and Yandex RCA. We used Naive bayes classifier (Weka package) with complex score to train ranking function. Complex score means that we divide one class from another by calculating score which considers place types. More precisely, description and website weights depend on a place type. 

---
#### csui01 
[**`Participants`**](./participants.md#fasilkomui), [**`Input`**](https://trec.nist.gov/results/trec22/context/csui01.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/csui01.pdf) 

- :material-rename: **Run ID:** csui01 
- :fontawesome-solid-user-group: **Participant:** fasilkomui 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b0abf9bf91595698cd30289cac8b2788` 
- :material-text: **Run description:** this run search to yelp and foursquare for user's preferred category, then perform re-rank based on descriptiveness(url, description, etc.) and attractiveness(rating, review count, etc.) of the place itself.. 

---
#### csui02 
[**`Participants`**](./participants.md#fasilkomui), [**`Input`**](https://trec.nist.gov/results/trec22/context/csui02.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/csui02.pdf) 

- :material-rename: **Run ID:** csui02 
- :fontawesome-solid-user-group: **Participant:** fasilkomui 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `84519f626be08e78989ed22bd9d55d69` 
- :material-text: **Run description:** This run search on Yelp and Foursquare data for places based on user's preferred category & context, then perform re-rank based on descriptiveness(url, description, etc.) and attractiveness(rating, review count, etc.) of the place itself, merge in round robin fashion to ensure diversity among top results.  

---
#### DuTH_A 
[**`Participants`**](./participants.md#duth), [**`Proceedings`**](./proceedings.md#duth-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/DuTH_A.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/DuTH_A.pdf) 

- :material-rename: **Run ID:** DuTH_A 
- :fontawesome-solid-user-group: **Participant:** DuTH 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/22/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `3e705fffa8909d3bff51305799e065c4` 
- :material-text: **Run description:** Suggestion model based on k-nearest neighbor algorithm (k-NN) weighted with tf-idf. 

---
#### DuTH_B 
[**`Participants`**](./participants.md#duth), [**`Proceedings`**](./proceedings.md#duth-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/DuTH_B.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/DuTH_B.pdf) 

- :material-rename: **Run ID:** DuTH_B 
- :fontawesome-solid-user-group: **Participant:** DuTH 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/22/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b478de336376436ee0a410b6f0e3470d` 
- :material-text: **Run description:** Suggestion model based on Rocchio algorithm. 

---
#### IBCosTop1 
[**`Participants`**](./participants.md#cwi), [**`Proceedings`**](./proceedings.md#cwi-and-tu-delft-notebook-trec-2013-contextual-suggestion-federated-web-search-kba-and-web-tracks), [**`Input`**](https://trec.nist.gov/results/trec22/context/IBCosTop1.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/IBCosTop1.pdf) 

- :material-rename: **Run ID:** IBCosTop1 
- :fontawesome-solid-user-group: **Participant:** CWI 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12full 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `aa4cd69bc182f18398cc24e96ac31bb2` 
- :material-text: **Run description:** first we extracted candidate documents from the ClueWeb12 that mentioned one of the context that we have. And we generated users profiles from the descriptions given in the examples. Then we computed the cosine similarit between users profiles and the candidate documents. Finally, we took the top 50 from the top 1000, where docs have titles and descriptions.  

---
#### IRIT.ClueWeb 
[**`Participants`**](./participants.md#irit), [**`Proceedings`**](./proceedings.md#irit-geocomp-and-liuppa-at-the-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/IRIT.ClueWeb.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/IRIT.ClueWeb.pdf) 

- :material-rename: **Run ID:** IRIT.ClueWeb 
- :fontawesome-solid-user-group: **Participant:** IRIT 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12cs 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `b9cdb2ea276841669bbd945820aa7295` 
- :material-text: **Run description:** Profiles were computed for the 562 users according to their votes.  Users were assigned one or more "categories" from WordNet and Google Places. Documents were retrieved for each profile with Terrier according to a query composed of the users' categories and their weight (used as a boost for the associated query term).  Results are at this point context-independent. Documents are then ranked for each context and user according to their Terrier score and their similarity to the user profile.  The description of a suggestion states the snippet of the suggested website. 

---
#### IRIT.OpenWeb 
[**`Participants`**](./participants.md#irit), [**`Proceedings`**](./proceedings.md#irit-geocomp-and-liuppa-at-the-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/IRIT.OpenWeb.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/IRIT.OpenWeb.pdf) 

- :material-rename: **Run ID:** IRIT.OpenWeb 
- :fontawesome-solid-user-group: **Participant:** IRIT 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/19/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `d106a58f3392139a2350b5e8cf2d616b` 
- :material-text: **Run description:** Profiles were computed for the 562 users according to their votes. Users were assigned one or more "categories" from WordNet and Google Places. Places were retrieved for the 50 contexts with Google Places (+ snippets from Bing). Each place was tagged with "categories" from WordNet and Google Places. For a given context, suggestions match the user's preferences by mapping the "categories" from the user and the places available around this context (distance computed between the two GPS coordinates).  The description of a suggestion states the type(s) of place, the address, distance and travel time (foot/car), the Points of Interest (POIs) around and a snippet of the suggested website. 

---
#### isirun 
[**`Participants`**](./participants.md#isiattrec), [**`Proceedings`**](./proceedings.md#a-simple-context-dependent-suggestion-system), [**`Input`**](https://trec.nist.gov/results/trec22/context/isirun.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/isirun.pdf) 

- :material-rename: **Run ID:** isirun 
- :fontawesome-solid-user-group: **Participant:** ISIatTREC 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `346f0a582de8faf32ec6796097d7151d` 
- :material-text: **Run description:** Google Places are used for fetching the context. Google search is used for the description. 

---
#### ming_1 
[**`Participants`**](./participants.md#pitt), [**`Proceedings`**](./proceedings.md#pitt-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/ming_1.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/ming_1.pdf) 

- :material-rename: **Run ID:** ming_1 
- :fontawesome-solid-user-group: **Participant:** PITT 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `d0cf2d99db3454dc921791459951dd0e` 
- :material-text: **Run description:** Based on the approaches of last year, our method includes three parts: 1) candidate datasets preparation; 2) feature extraction; and 3) ranking. We search for the candidate data from Yelp and Google search engine. The vector space model is used to compute the similarity between each candidate data and example according to their descriptions. Apart from the similarity, other four features, which are lv2_category (category from Yelp), lv1_category (classify the category from Yelp manually), rating (general popularity) and distance (the distance between the suggestion and the location of users), are extracted. In the third part, we construct linear regression model on the judged data of last year, getting the weighting parameter of each feature, and compute the score of each candidate suggestion for ranking.  

---
#### ming_2 
[**`Participants`**](./participants.md#pitt), [**`Proceedings`**](./proceedings.md#pitt-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/ming_2.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/ming_2.pdf) 

- :material-rename: **Run ID:** ming_2 
- :fontawesome-solid-user-group: **Participant:** PITT 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `16a3f5a375023888604271d2a7c59352` 
- :material-text: **Run description:** Based on the approaches of last year, our method includes three parts: 1) candidate datasets preparation; 2) feature extraction; and 3) ranking. We search for the candidate data from Yelp and Google search engine. The vector space model is used to compute the similarity between each candidate data and example according to their descriptions. Apart from the similarity, other four features, which are lv2_category (category from Yelp), lv1_category (classify the category from Yelp manually), rating (general popularity) and distance (the distance between the suggestion and the location of users), are extracted. In the third part, we construct linear regression model on the judged data of last year, getting the weighting parameter of each feature, and compute the score of each candidate suggestion for ranking.  

---
#### run01 
[**`Participants`**](./participants.md#icmc_usp), [**`Input`**](https://trec.nist.gov/results/trec22/context/run01.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/run01.pdf) 

- :material-rename: **Run ID:** run01 
- :fontawesome-solid-user-group: **Participant:** ICMC_USP 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12cs 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `467726cad6bc53abf4f0cfe88788c030` 
- :material-text: **Run description:** We extracted interesting and non interesting keywords from the examples, and based on them, we created personalized queries for each user. Then, we used the Lucene Search Engine to query the set of attractions based on the descriptions available on the websites. The set of documents was created based on the ClueQWeb12-CS, which was filtered using the Google Places API. 

---
#### RUN1 
[**`Participants`**](./participants.md#ictnet), [**`Proceedings`**](./proceedings.md#ictnet-at-context-suggestion-track-trec-2013), [**`Input`**](https://trec.nist.gov/results/trec22/context/RUN1.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/RUN1.pdf) 

- :material-rename: **Run ID:** RUN1 
- :fontawesome-solid-user-group: **Participant:** ICTNET 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12cs 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `935a3693a287e591e8aaeb5ef13e7f3b` 
- :material-text: **Run description:** Results based on geographical information. 

---
#### RUN2 
[**`Participants`**](./participants.md#ictnet), [**`Proceedings`**](./proceedings.md#ictnet-at-context-suggestion-track-trec-2013), [**`Input`**](https://trec.nist.gov/results/trec22/context/RUN2.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/RUN2.pdf) 

- :material-rename: **Run ID:** RUN2 
- :fontawesome-solid-user-group: **Participant:** ICTNET 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** clueweb12cs 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `4c7e0e07e3468266fe2f8ec34b1f4985` 
- :material-text: **Run description:** geographical information + users' preference 

---
#### simpleScore 
[**`Participants`**](./participants.md#ulugano), [**`Proceedings`**](./proceedings.md#university-of-lugano-at-the-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/simpleScore.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/simpleScore.pdf) 

- :material-rename: **Run ID:** simpleScore 
- :fontawesome-solid-user-group: **Participant:** ULugano 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/22/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `616df0152c08fd5b68af8d61c7b315ea` 
- :material-text: **Run description:** Main source is Google Place. Descriptions are fetched from Open Web and Yandex RCA. We used Naive bayes classifier with simple score to train ranking function. Simple score means that we divide one class from another by calculating simple score. 

---
#### UAmsTF30WU 
[**`Participants`**](./participants.md#uamsterdam), [**`Proceedings`**](./proceedings.md#university-of-amsterdam-at-the-trec-2013-contextual-suggestion-track-learning-user-preferences-from-wikitravel-categories), [**`Input`**](https://trec.nist.gov/results/trec22/context/UAmsTF30WU.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/UAmsTF30WU.pdf) 

- :material-rename: **Run ID:** UAmsTF30WU 
- :fontawesome-solid-user-group: **Participant:** UAmsterdam 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `4541ad7ee715ab9d77ad6e01dfcf80a7` 
- :material-text: **Run description:** Suggestions from Wikitravel pages of all US cities are ranked based on description of the provided examples. For a particular profile, the rankings of positive (score 3 or 4) examples are merged to a single ranked list of suggestions per user. The suggestions are then filtered on location. 

---
#### udel_run_D 
[**`Participants`**](./participants.md#udel), [**`Input`**](https://trec.nist.gov/results/trec22/context/udel_run_D.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/udel_run_D.pdf) 

- :material-rename: **Run ID:** udel_run_D 
- :fontawesome-solid-user-group: **Participant:** udel 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `5aa7376cc5410c3ef5905223c31c83be` 
- :material-text: **Run description:** Yelp API was used for training purposes. Each example suggestion was categorized using Yelp API. Based upon each users preferences, keywords were appended to each profile. For each keyword and context combination, Results were retrieved using Google Place API. Round Robin approach was used to maintain diversity while selecting the top 50 suggestions for each user. 

---
#### udel_run_SD 
[**`Participants`**](./participants.md#udel), [**`Input`**](https://trec.nist.gov/results/trec22/context/udel_run_SD.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/udel_run_SD.pdf) 

- :material-rename: **Run ID:** udel_run_SD 
- :fontawesome-solid-user-group: **Participant:** udel 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `111b1c0ed51c573903d02684cdbf0f7b` 
- :material-text: **Run description:** Yelp API was used for training purposes. Each example suggestion was categorized using Yelp API. Based upon each users preferences, keywords were appended to each profile. For each keyword and context combination, Results were retrieved using Google Place API. Each list was sorted on the basis of Google Places rating. Round Robin approach was used to maintain diversity while selecting the top 50 suggestions for each user. 

---
#### UDInfoCS1 
[**`Participants`**](./participants.md#udel_fang), [**`Proceedings`**](./proceedings.md#an-opinion-aware-approach-to-contextual-suggestion), [**`Input`**](https://trec.nist.gov/results/trec22/context/UDInfoCS1.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/UDInfoCS1.pdf) 

- :material-rename: **Run ID:** UDInfoCS1 
- :fontawesome-solid-user-group: **Participant:** udel_fang 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/22/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `eb32aecb0165133a239c992eb52e07dd` 
- :material-text: **Run description:** Candidates are crawled from Yelp. User profiles are constructed based on the summary reviews in order to generalize what a user likes or dislikes, and the candidate suggestions are then ranked based on their similarity to the user profiles. Descriptions are generated based on the category, meta-description and the content of the website, reviews, and examples that the user liked. 

---
#### UDInfoCS2 
[**`Participants`**](./participants.md#udel_fang), [**`Proceedings`**](./proceedings.md#an-opinion-aware-approach-to-contextual-suggestion), [**`Input`**](https://trec.nist.gov/results/trec22/context/UDInfoCS2.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/UDInfoCS2.pdf) 

- :material-rename: **Run ID:** UDInfoCS2 
- :fontawesome-solid-user-group: **Participant:** udel_fang 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/22/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `ede3249449a7235706aa155ec85656f7` 
- :material-text: **Run description:** Candidates are crawled from Yelp. User profiles are constructed based on the unique terms from the reviews. Candidates are ranked based on their similarity to the user profiles. Descriptions are generated based on the category, meta-description of the website, reviews and examples. 

---
#### uncsils_base 
[**`Participants`**](./participants.md#unc_sils), [**`Proceedings`**](./proceedings.md#a-nearest-neighbor-approach-to-contextual-suggestion), [**`Input`**](https://trec.nist.gov/results/trec22/context/uncsils_base.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/uncsils_base.pdf) 

- :material-rename: **Run ID:** uncsils_base 
- :fontawesome-solid-user-group: **Participant:** UNC_SILS 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `cc7d6f38046f41cb07cd06acece6ed41` 
- :material-text: **Run description:** Each candidate recommendation was scored using the weighted-average rating given to documents in the user's profile.  The weights given to documents in the profile were computed using the cosine similarity between the candidate recommendation and the profile document.  The cosine similarity was computed using tf.idf term-weights.  

---
#### uncsils_param 
[**`Participants`**](./participants.md#unc_sils), [**`Proceedings`**](./proceedings.md#a-nearest-neighbor-approach-to-contextual-suggestion), [**`Input`**](https://trec.nist.gov/results/trec22/context/uncsils_param.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/uncsils_param.pdf) 

- :material-rename: **Run ID:** uncsils_param 
- :fontawesome-solid-user-group: **Participant:** UNC_SILS 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `34ec8630b8cd679989da74e661f55c9d` 
- :material-text: **Run description:** Each candidate recommendation was scored using the weighted-average rating given to documents in the user's profile.  The weights given to documents in the profile were computed using the cosine similarity between the candidate recommendation and the profile document.  The cosine similarity was computed using tf.idf term-weights.  The score was boosted using the rating given to the profile document that was the most similar to the candidate recommendation.  

---
#### uogTrCFP 
[**`Participants`**](./participants.md#uogtr), [**`Proceedings`**](./proceedings.md#university-of-glasgow-at-trec-2013-experiments-with-terrier-in-contextual-suggestion-temporal-summarisation-and-web-tracks), [**`Input`**](https://trec.nist.gov/results/trec22/context/uogTrCFP.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/uogTrCFP.pdf) 

- :material-rename: **Run ID:** uogTrCFP 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `9a875b74c05c78b1d2f97aa0f7fee921` 
- :material-text: **Run description:** Ranking venues using similarity measures between user profile and the venue description and the popularity of the venue. 

---
#### uogTrCFX 
[**`Participants`**](./participants.md#uogtr), [**`Proceedings`**](./proceedings.md#university-of-glasgow-at-trec-2013-experiments-with-terrier-in-contextual-suggestion-temporal-summarisation-and-web-tracks), [**`Input`**](https://trec.nist.gov/results/trec22/context/uogTrCFX.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/uogTrCFX.pdf) 

- :material-rename: **Run ID:** uogTrCFX 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/24/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `4946a01a939eeb52f5ff133bb8390087` 
- :material-text: **Run description:** This run uses a diversification approach to re-rank the venues for a given user such that they cover the categories of the user's interest 

---
#### york13cr1 
[**`Participants`**](./participants.md#york), [**`Proceedings`**](./proceedings.md#york-university-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/york13cr1.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/york13cr1.pdf) 

- :material-rename: **Run ID:** york13cr1 
- :fontawesome-solid-user-group: **Participant:** YORK 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `39634453a67873d6622ce9184f68c07b` 
- :material-text: **Run description:** This run is based on Google places API where only the user context is considered for returning the top 50 attractions. 

---
#### york13cr2 
[**`Participants`**](./participants.md#york), [**`Proceedings`**](./proceedings.md#york-university-at-trec-2013-contextual-suggestion-track), [**`Input`**](https://trec.nist.gov/results/trec22/context/york13cr2.gz), [**`Appendix`**](https://trec.nist.gov/pubs/trec22/appendices/context/york13cr2.pdf) 

- :material-rename: **Run ID:** york13cr2 
- :fontawesome-solid-user-group: **Participant:** YORK 
- :material-format-text: **Track:** Contextual Suggestion 
- :material-calendar: **Year:** 2013 
- :material-upload: **Submission:** 7/23/2013 
- :fontawesome-solid-user-gear: **Type:** openWeb 
- :material-text-search: **Task:** main 
- :material-fingerprint: **MD5:** `e3edfc0eda68883fdf45480253a59428` 
- :material-text: **Run description:** This run is based on exploiting a semantic user profile for personalized recommendation. The user profile is composed of a set of categories issued from the Open Directory Project (ODP) ontology. Each category in the user profile is represented with terms based on positive and negative attractions previously  rated by the user. For each context-profile pair, we rerank the top 50 suggestions returned by Google places API using the user profile. Each suggestion is scored according to how well it matches each of the categories in the user profile. 

---
