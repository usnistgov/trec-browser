# Overview - LiveQA 2015

[`Proceedings`](./proceedings.md), [`Data`](./data.md), [`Runs`](./runs.md), [`Participants`](./participants.md)

{==

The automated question answering (QA) track, one of the most popular tracks in TREC for many years, has focused on the task of providing automatic answers for human questions. The track primarily dealt with factual questions, and the answers provided by participants were extracted from a corpus of News articles. While the task evolved to model increasingly realistic information needs, addressing question series, list questions, and even interactive feedback, a major limitation remained: the questions did not directly come from real users, in real time. The LiveQA track, conducted for the first time this year, focused on realtime question answering for real-user questions. Real user questions, i.e., fresh questions submitted on the Yahoo Answers (YA) site that have not yet been answered, were sent to the participant systems, which provided an answer in real time. Returned answers were judged by TREC editors on a 4-level Likert scale

==}

:fontawesome-solid-user-group: **Track coordinators:**

- Eugene Agichtein - Emory University 
- David Carmel, Dan Pelleg - Yahoo Labs 
- Yuval Pinter - Yahoo Labs 
- Donna Harman - National Institute of Standards and Technology (NIST) 

:fontawesome-solid-globe: **Track Web Page:** [`https://web.archive.org/web/20160219234556/https://sites.google.com/site/trecliveqa2015/`](https://web.archive.org/web/20160219234556/https://sites.google.com/site/trecliveqa2015/) 

---

