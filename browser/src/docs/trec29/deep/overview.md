# Overview - Deep Learning 2020

[`Proceedings`](./proceedings.md), [`Data`](./data.md), [`Results`](./results.md), [`Runs`](./runs.md), [`Participants`](./participants.md)

{==

This is the second year of the TREC Deep Learning Track, with the goal of studying ad hoc ranking in the large training data regime. We again have a document retrieval task and a passage retrieval task, each with hundreds of thousands of human-labeled training queries. We evaluate using singleshot TREC-style evaluation, to give us a picture of which ranking methods work best when large data is available, with much more comprehensive relevance labeling on the small number of test queries. This year we have further evidence that rankers with BERT-style pretraining outperform other rankers in the large data regime.

==}

:fontawesome-solid-user-group: **Track coordinator(s):**

- Nick Craswell, Microsoft AI & Research 
- Bhaskar Mitra, Microsoft AI & Research 
- Bhaskar Mitra, University College London 
- Emine Yilmaz, University College London 
-  Daniel Campos, University of Illinois Urbana-Champaign 

:material-text-search: **Tasks:**

- `docs`: Document Ranking 
- `passages`: Passage Ranking 

:fontawesome-solid-globe: **Track Web Page:** [`https://microsoft.github.io/msmarco/TREC-Deep-Learning`](https://microsoft.github.io/msmarco/TREC-Deep-Learning) 

---

