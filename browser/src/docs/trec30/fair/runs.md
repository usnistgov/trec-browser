# Runs - Fair Ranking 2021 

#### 1step_pair 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.1step_pair.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.1step_pair) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/1step_pair.pdf) 

- :material-rename: **Run ID:** 1step_pair 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/3/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `163470b4bb08462ed28f9a9858509942` 
- :material-text: **Run description:** A static method with one filtering step: first 4500 top-ranked docs are selected. 

---
#### 1step_pair_list 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.1step_pair_list.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.1step_pair_list) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/1step_pair_list.pdf) 

- :material-rename: **Run ID:** 1step_pair_list 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/3/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `33b6d4de3944ec51609ff42bf2e5a128` 
- :material-text: **Run description:** A static method with one filtering step: first 4500 top-ranked docs are selected. The best-performing method from two different rankers is selected. 

---
#### 2step_pair 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.2step_pair.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.2step_pair) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/2step_pair.pdf) 

- :material-rename: **Run ID:** 2step_pair 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/3/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `6c51fa83c313431785e214465044f5ce` 
- :material-text: **Run description:** A static method with two filtering steps: first 4500 top-ranked docs are selected, then the union of the output of two different fair rankers is considered (around 1200 docs). 

---
#### 2step_pair_list 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.2step_pair_list.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.2step_pair_list) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/2step_pair_list.pdf) 

- :material-rename: **Run ID:** 2step_pair_list 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/3/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `8c4a6c44843e984f5c52eeb4f93646ad` 
- :material-text: **Run description:** A static method with two filtering steps: first 4500 top-ranked docs are selected, then the union of the output of two different fair rankers is considered (around 1200 docs). 

---
#### pl_control_0.6 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.pl_control_0.6.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.pl_control_0.6) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/pl_control_0.6.pdf) 

- :material-rename: **Run ID:** pl_control_0.6 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `71868ba69e56875f73389538962f94d2` 
- :material-text: **Run description:** 1) The method for this run is randomized. 2) For a given query, across various stages, ranking at the current stage depends on the ranked list from the previous stage. In each iteration we compute a score for each of the top-K documents in the current state, based on the expected exposure of each group so far (we compute an advantage) and the original estimated relevance score. Then we sample documents with respect to this score. 3) It uses the article's quality score in the ranking. 

---
#### pl_control_0.8 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.pl_control_0.8.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.pl_control_0.8) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/pl_control_0.8.pdf) 

- :material-rename: **Run ID:** pl_control_0.8 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `6e83058d006e8ccdecf828b14944981a` 
- :material-text: **Run description:** 1) The method for this run is randomized. 2) For a given query, across various stages, ranking at the current stage depends on the ranked list from the previous stage. In each iteration we compute a score for each of the top-K documents in the current state, based on the expected exposure of each group so far (we compute an advantage) and the original estimated relevance score. Then we sample documents with respect to this score. 3) It uses the article's quality score in the ranking. 

---
#### pl_control_0.92 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.pl_control_0.92.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.pl_control_0.92) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/pl_control_0.92.pdf) 

- :material-rename: **Run ID:** pl_control_0.92 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `f71ca48e5c289573bfd273bad883a013` 
- :material-text: **Run description:** 1) The method for this run is randomized. 2) For a given query, across various stages, ranking at the current stage depends on the ranked list from the previous stage. In each iteration we compute a score for each of the top-K documents in the current state, based on the expected exposure of each group so far (we compute an advantage) and the original estimated relevance score. Then we sample documents with respect to this score. 3) It uses the article's quality score in the ranking. 

---
#### PL_IRLab_05 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.PL_IRLab_05.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.PL_IRLab_05) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/PL_IRLab_05.pdf) 

- :material-rename: **Run ID:** PL_IRLab_05 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/3/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `40b9ce698ba4a9f1cfec9a2a3842ba01` 
- :material-text: **Run description:** randomized method with a two-staged Plackett-Luce sampling. Work needed is multiplied by the relevance. 

---
#### PL_IRLab_07 
[**`Participants`**](./participants.md#irlab-amsterdam) | [**`Proceedings`**](./proceedings.md#the-university-of-amsterdam-at-the-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.PL_IRLab_07.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.PL_IRLab_07) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/PL_IRLab_07.pdf) 

- :material-rename: **Run ID:** PL_IRLab_07 
- :fontawesome-solid-user-group: **Participant:** IRLab-Amsterdam 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/3/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `66f4ee469c3f25048e4427f37237d193` 
- :material-text: **Run description:** randomized method with a two-staged Plackett-Luce sampling. Work needed is multiplied by the relevance. 

---
#### RMITRet 
[**`Participants`**](./participants.md#rmit-ir) | [**`Proceedings`**](./proceedings.md#rmit-at-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.RMITRet.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.RMITRet) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/RMITRet.pdf) 

- :material-rename: **Run ID:** RMITRet 
- :fontawesome-solid-user-group: **Participant:** RMIT-IR 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `d819844c043d2156a02203aad96bc739` 
- :material-text: **Run description:** We used the pyserini package to index the documents with Lucene inverted indexes and also for retrieval with BM25. 

---
#### RMITRetRerank_1 
[**`Participants`**](./participants.md#rmit-ir) | [**`Proceedings`**](./proceedings.md#rmit-at-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.RMITRetRerank_1.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.RMITRetRerank_1) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/RMITRetRerank_1.pdf) 

- :material-rename: **Run ID:** RMITRetRerank_1 
- :fontawesome-solid-user-group: **Participant:** RMIT-IR 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `9a8f1d04faf01ce9f9bbc1b289faf6fc` 
- :material-text: **Run description:** All indexing was done using Lucene inverted indexes from the pyserini package. Retrieval was performed with BM25 from pyserini and re-ranked using implicit diversification technique (MMR) with default lambda value = 0.5. Since implicit diversification was used no groups such as geographic locations or topic categories were involved while re-ranking. 

---
#### RMITRetRerank_2 
[**`Participants`**](./participants.md#rmit-ir) | [**`Proceedings`**](./proceedings.md#rmit-at-trec-2021-fair-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.RMITRetRerank_2.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.RMITRetRerank_2) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/RMITRetRerank_2.pdf) 

- :material-rename: **Run ID:** RMITRetRerank_2 
- :fontawesome-solid-user-group: **Participant:** RMIT-IR 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `c43f6aa8623bd995c6e6e45071f03ac1` 
- :material-text: **Run description:** All indexing was done using Lucene inverted indexes from the pyserini package. Retrieval was performed with BM25 from pyserini and re-ranked using implicit diversification technique (MMR) with lambda value = 0.3. Since implicit diversification was used no groups such as geographic locations or topic categories were involved while re-ranking.  

---
#### RUN1 
[**`Participants`**](./participants.md#tkb48) | [**`Proceedings`**](./proceedings.md#tkb48-at-trec-2021-fairness-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.RUN1.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.RUN1) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/RUN1.pdf) 

- :material-rename: **Run ID:** RUN1 
- :fontawesome-solid-user-group: **Participant:** TKB48 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/1/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `01d1760804b67bd002814715c7c6c8fd` 
- :material-text: **Run description:** 1. Rerank the ranking from BM25 (2000 documents for init ranking) 2. Choose document one by one 3. Calculate fairness based on how many documents still need to be put into the ranking. More need higher score. 4. Put document with highest score one by one.  

---
#### RUN_task2 
[**`Participants`**](./participants.md#tkb48) | [**`Proceedings`**](./proceedings.md#tkb48-at-trec-2021-fairness-ranking-track) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.RUN_task2.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.RUN_task2) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/RUN_task2.pdf) 

- :material-rename: **Run ID:** RUN_task2 
- :fontawesome-solid-user-group: **Participant:** TKB48 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/1/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `8c521c31bd914b1bff090535ae436402` 
- :material-text: **Run description:** 1. Rerank the ranking from BM25 (5000 documents for init ranking) 2. Choose document one by one 3. Calculate fairness based on how many documents still need to be put into the ranking. More need higher score. 4. Because we need to return 100 rankings. We focus on first ranking, and choose one document with highest score (Which combine the relevance and fairness and quality score). Then we focus on second ranking, and choose one document with the highest score.  ... After we put one document for 100 rankings, we decide the second document for rankings one by one.  

---
#### UoGTrDExpDisLT1 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrDExpDisLT1.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrDExpDisLT1) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrDExpDisLT1.pdf) 

- :material-rename: **Run ID:** UoGTrDExpDisLT1 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `b34beaaa320df15f5b86475a55eef2fb` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both the geographic location attribute and an inferred demographic attribute. The approach combines the first-pass retrieval with a tailored diversification plus data fusion fairness component. The fairness component is optimised to take into consideration a protected groups distribution in the background collection and the total relevance of the group in the candidate results set. This run differs from our UoGTrDivExpDispT1 run in that it integrates a parameter for learning the importance of the group relevances and background distributions.    

---
#### UoGTrDExpDisT1 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrDExpDisT1.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrDExpDisT1) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrDExpDisT1.pdf) 

- :material-rename: **Run ID:** UoGTrDExpDisT1 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `6099caca4e6c38505b0a1af46e05e957` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both the geographic location attribute and an inferred demographic attribute. The approach combines the first-pass retrieval scores with a tailored diversification plus data fusion fairness component. The fairness component is optimised to take into consideration a protected groups distribution in the background collection and the total relevance of the group in the candidate results set. 

---
#### UoGTrDExpDisT2 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrDExpDisT2.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrDExpDisT2) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrDExpDisT2.pdf) 

- :material-rename: **Run ID:** UoGTrDExpDisT2 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `f1778245b833c08f378e5d2f5574e13c` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both the geographic location attribute and an inferred demographic attribute. The approach combines the first-pass retrieval with a tailored diversification and data fusion fairness component. The fairness component is optimised to take into consideration a protected groups distribution in the background collection and the total relevance of the group in the candidate results set. For a sequence of repeated queries, the approach continually optimises the selection of documents to minimise the disparity between a groups expected and actual exposures. 

---
#### UoGTrDivPropT1 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrDivPropT1.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrDivPropT1) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrDivPropT1.pdf) 

- :material-rename: **Run ID:** UoGTrDivPropT1 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `4c18eaf5cbdf6012022d63d6ea422152` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both geographic location and an inferred demographic attribute. The approach combines the first-pass retrieval relevance scores with a tailored diversification plus data fusion approach to prioritise highly relevant documents while matching the distributions of the protected groups in the generated ranking to their distributions in the background population. 

---
#### UoGTrDivPropT2 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrDivPropT2.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrDivPropT2) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrDivPropT2.pdf) 

- :material-rename: **Run ID:** UoGTrDivPropT2 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `afbe32a751e21a84fffa2627e7098205` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both geographic location and an inferred demographic attribute. The approach combines the first-pass retrieval relevance and work-needed scores with a tailored diversification plus data fusion approach to prioritise highly relevant documents while matching the distributions of the protected groups to their distributions in the background population. For repeated queries, the approach continually optimises the selection of documents to minimise the divergence, or skew, in the distributions of the protected groups over all of the rankings within a sequence, compared to the background population.  

---
#### UoGTrDRelDiT1 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrDRelDiT1.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrDRelDiT1) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrDRelDiT1.pdf) 

- :material-rename: **Run ID:** UoGTrDRelDiT1 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `3bd8f532f283c07da392956adc410a56` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both the geographic location attribute and an inferred demographic attribute. The approach combines the first-pass retrieval relevance score with a tailored diversification plus data fusion approach that prioritises highly relevant documents, while allocating positions in the generated ranking to a protected group proportionally with respect to the total relevance score of the group within the candidate results set.   

---
#### UoGTrDRelDiT2 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrDRelDiT2.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrDRelDiT2) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrDRelDiT2.pdf) 

- :material-rename: **Run ID:** UoGTrDRelDiT2 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `2d972b5e2980ab0b7463daa2b0fa4555` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both the geographic location attribute and an inferred demographic attribute. The approach combines the first-pass retrieval relevance and work-needed scores with a tailored diversification plus data fusion approach that prioritises highly relevant documents, while allocating positions in the ranking to a protected group proportionally with respect to the total relevance score of the group within the candidate results set. For repeated queries, the approach continually optimises the selection of documents to  

---
#### UoGTrLambT2 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrLambT2.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrLambT2) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrLambT2.pdf) 

- :material-rename: **Run ID:** UoGTrLambT2 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/3/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `34c69ac7024b61798f6e733a644d25b1` 
- :material-text: **Run description:** This run builds on the Terrier.org IR platform, to rank documents by relevance before applying a fairness component that aims to be fair to both the geographic location attribute and an inferred demographic attribute. The approach combines the first-pass retrieval with a tailored diversification and data fusion fairness component. The fairness component is optimised to take into consideration a protected groups distribution in the background collection and the total relevance of the group in the candidate results set. For a sequence of repeated queries, the approach continually optimises the selection of documents to minimise the disparity between a groups expected and actual exposures. This run differs from our UoGTrDivExpDispT2 run in that it integrates a parameter for learning the importance of the group relevances and background distributions.   

---
#### UoGTrRelT1 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrRelT1.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrRelT1) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrRelT1.pdf) 

- :material-rename: **Run ID:** UoGTrRelT1 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** coordinators 
- :material-fingerprint: **MD5:** `4a93e114c74c6a51d6a81ffd62311c0f` 
- :material-text: **Run description:** This run simply consists in ranking the documents according to their relevance with respect to the query. No fairness component is explicitly enforced. 

---
#### UoGTrRelT2 
[**`Participants`**](./participants.md#uogtr) | [**`Input`**](https://trec.nist.gov/results/trec30/fair/input.UoGTrRelT2.gz) | [**`Summary`**](https://trec.nist.gov/results/trec30/fair/summary.UoGTrRelT2) | [**`Appendix`**](https://trec.nist.gov/pubs/trec30/appendices/fair/UoGTrRelT2.pdf) 

- :material-rename: **Run ID:** UoGTrRelT2 
- :fontawesome-solid-user-group: **Participant:** uogTr 
- :material-format-text: **Track:** Fair Ranking 
- :material-calendar: **Year:** 2021 
- :material-upload: **Submission:** 8/2/2021 
- :material-text-search: **Task:** editors 
- :material-fingerprint: **MD5:** `17f9e7e68841b308f4466363a54e0e19` 
- :material-text: **Run description:** This run simply consists in ranking, for each instance of a query in the sequence, the documents according to their relevance with respect to the query. No fairness component is explicitly enforced. 

---
