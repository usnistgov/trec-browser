# Runs - Conversational Assistance 2022 

#### CNC_AD 
[**`Results`**](./results.md#cnc_ad), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_AD.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AD.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AD.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_AD.pdf) 

- :material-rename: **Name:** CNC_AD 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `9de092b1acc72d6252b685eb91bea3c4` 
- :material-text: **Run description:** CNC_AD: automatic rewritten, convDPR, pointwise reranking 

---
#### CNC_AD-C 
[**`Results`**](./results.md#cnc_ad-c), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_AD-C.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AD-C.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AD-C.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_AD-C.pdf) 

- :material-rename: **Name:** CNC_AD-C 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `78fdcb526a51858b2630935fcfbec9ad` 
- :material-text: **Run description:** CNC_AD-C: conversational DPR. conversational reranking model 

---
#### CNC_AS 
[**`Results`**](./results.md#cnc_as), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_AS.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AS.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AS.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_AS.pdf) 

- :material-rename: **Name:** CNC_AS 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `b171999cb8ef9f8ca8623cf25d44a33c` 
- :material-text: **Run description:** CNC_As: automatic rewritten, sparse doc retrieval, pointwise reranking 

---
#### CNC_AS-C 
[**`Results`**](./results.md#cnc_as-c), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_AS-C.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AS-C.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_AS-C.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_AS-C.pdf) 

- :material-rename: **Name:** CNC_AS-C 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `3b8d9bd5ac7693e2666ac6efac927bd6` 
- :material-text: **Run description:** CNC_AS-C: Automatic rewritten from t5ntr, conversational reranking model 

---
#### CNC_cqg 
[**`Results`**](./results.md#cnc_cqg), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_cqg.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_cqg.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_cqg.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_cqg.pdf) 

- :material-rename: **Name:** CNC_cqg 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/21/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** mixed 
- :material-fingerprint: **MD5:** `a901b3eabe5084304ad3b81adadc99af` 
- :material-text: **Run description:** T5 clarification question generation,  Query likelihood Estimation 

---
#### CNC_kwqlm2_cqg 
[**`Results`**](./results.md#cnc_kwqlm2_cqg), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_kwqlm2_cqg.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_kwqlm2_cqg.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_kwqlm2_cqg.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_kwqlm2_cqg.pdf) 

- :material-rename: **Name:** CNC_kwqlm2_cqg 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/21/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** mixed 
- :material-fingerprint: **MD5:** `bd671b87c3cbfd7ba5791efc54fd79f0` 
- :material-text: **Run description:** zero shot dense retrieval, T5 clarification question generation 

---
#### CNC_kwqlm_cqg 
[**`Results`**](./results.md#cnc_kwqlm_cqg), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_kwqlm_cqg.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_kwqlm_cqg.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_kwqlm_cqg.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_kwqlm_cqg.pdf) 

- :material-rename: **Name:** CNC_kwqlm_cqg 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/21/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** mixed 
- :material-fingerprint: **MD5:** `79b73c5c721179ef16ec6309180787e5` 
- :material-text: **Run description:** Zero shot dense retrieval, T5 clarification question generation 

---
#### CNC_MD-C 
[**`Results`**](./results.md#cnc_md-c), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_MD-C.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_MD-C.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_MD-C.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_MD-C.pdf) 

- :material-rename: **Name:** CNC_MD-C 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `3cbcd0c712d68c66cc7390615ca0cfdf` 
- :material-text: **Run description:** CNC_MD-C: manual rewritten, convDPR, conversational pointwise reranking 

---
#### CNC_MS-C 
[**`Results`**](./results.md#cnc_ms-c), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-conversational-assistance-track-cast), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNC_MS-C.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_MS-C.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNC_MS-C.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNC_MS-C.pdf) 

- :material-rename: **Name:** CNC_MS-C 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `288f53ee589b676986be6ede34d0f148` 
- :material-text: **Run description:** CNC_MS-C: manual rewritten, spare doc retrieval, conversational pointwise reranking 

---
#### CNR_run1 
[**`Results`**](./results.md#cnr_run1), [**`Participants`**](./participants.md#cnr), [**`Proceedings`**](./proceedings.md#context-propagation-in-conversational-search-utterances-participation-of-the-cnr-team-in-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNR_run1.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run1.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run1.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNR_run1.pdf) 

- :material-rename: **Name:** CNR_run1 
- :fontawesome-solid-user-group: **Participant:** CNR 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `4cc13a24c69634d05af5ac76a63fef8a` 
- :material-text: **Run description:** Indexing and querying with PyTerrier 0.7.1, based on Terrier 5.6, using traditional unsupervised sparse retrieval (e.g., DPH). The current user's utterance is enriched with topics extracted from the previous automatically rewritten utterance provided by CAsT.  Only utterances are used for the expansion. 

---
#### CNR_run2 
[**`Results`**](./results.md#cnr_run2), [**`Participants`**](./participants.md#cnr), [**`Proceedings`**](./proceedings.md#context-propagation-in-conversational-search-utterances-participation-of-the-cnr-team-in-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNR_run2.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run2.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run2.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNR_run2.pdf) 

- :material-rename: **Name:** CNR_run2 
- :fontawesome-solid-user-group: **Participant:** CNR 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `60e29809943cd7f23a5a787d1d924391` 
- :material-text: **Run description:** Indexing and querying with PyTerrier 0.7.1, based on Terrier 5.6, using traditional unsupervised sparse retrieval (e.g., DPH). The current user's utterance is enriched with topics extracted from the previous manually rewritten utterance provided by CAsT.  Only utterances are used for the expansion. 

---
#### CNR_run3 
[**`Results`**](./results.md#cnr_run3), [**`Participants`**](./participants.md#cnr), [**`Proceedings`**](./proceedings.md#context-propagation-in-conversational-search-utterances-participation-of-the-cnr-team-in-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNR_run3.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run3.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run3.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNR_run3.pdf) 

- :material-rename: **Name:** CNR_run3 
- :fontawesome-solid-user-group: **Participant:** CNR 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `3ec6ededaba73d422858eb7d9dcd4fc8` 
- :material-text: **Run description:** Indexing and querying with PyTerrier 0.7.1, based on Terrier 5.6, using traditional unsupervised sparse retrieval (e.g., DPH). The current user's utterance is enriched with terms extracted from the first sentence of the response to the previous utterance. Utterances plus their responses are used for the expansion.  

---
#### CNR_run4 
[**`Results`**](./results.md#cnr_run4), [**`Participants`**](./participants.md#cnr), [**`Proceedings`**](./proceedings.md#context-propagation-in-conversational-search-utterances-participation-of-the-cnr-team-in-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.CNR_run4.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run4.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.CNR_run4.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/CNR_run4.pdf) 

- :material-rename: **Name:** CNR_run4 
- :fontawesome-solid-user-group: **Participant:** CNR 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `3816da0dde3290e8551d8613c71e0c5d` 
- :material-text: **Run description:** Indexing and querying with PyTerrier 0.7.1, based on Terrier 5.6, using traditional unsupervised sparse retrieval (e.g., DPH). The current user's utterance is enriched with the top-5 frequent terms extracted from the response to the previous utterance. Utterances plus their responses are used for the expansion. 

---
#### combine0.5 
[**`Results`**](./results.md#combine05), [**`Participants`**](./participants.md#heatwave), [**`Proceedings`**](./proceedings.md#university-of-cambridge-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.combine0.5.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.combine0.5.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.combine0.5.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/combine0.5.pdf) 

- :material-rename: **Name:** combine0.5 
- :fontawesome-solid-user-group: **Participant:** HEATWAVE 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `53860e6de86934d5a541873e244c652f` 
- :material-text: **Run description:** Current and previous utterances are concatenated and used for BM25 (top 3k). expanded query (trained with CANARD) used in monotoT5 reranker.  Top 30 passages further reranked using duoT5. Score interpolated for top 30 using monot5 and duot5. answer span extracted using SQuAD2. 

---
#### DEI-run1 
[**`Results`**](./results.md#dei-run1), [**`Participants`**](./participants.md#iiia-unipd), [**`Proceedings`**](./proceedings.md#question-answering-based-query-expansion-for-conversational-search-iiia-unipd-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.DEI-run1.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run1.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run1.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/DEI-run1.pdf) 

- :material-rename: **Name:** DEI-run1 
- :fontawesome-solid-user-group: **Participant:** iiia-unipd 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/25/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `affe726be05e43cfdf1ae6248d8a3c1e` 
- :material-text: **Run description:** NeuralCoref to resolve coreferences, POS tagging based on previous utterances to carry out query expansion.  BM25 for first stage ranking. BERT for query understanding and last re-ranking based on first stage rank   

---
#### DEI-run2 
[**`Results`**](./results.md#dei-run2), [**`Participants`**](./participants.md#iiia-unipd), [**`Proceedings`**](./proceedings.md#question-answering-based-query-expansion-for-conversational-search-iiia-unipd-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.DEI-run2.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run2.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run2.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/DEI-run2.pdf) 

- :material-rename: **Name:** DEI-run2 
- :fontawesome-solid-user-group: **Participant:** iiia-unipd 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/25/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `bac1cefef53f92525fd4197b9f19d34b` 
- :material-text: **Run description:** NeuralCoref to resolve coreferences, POS tagging based on previous utterances to carry out query expansion.  BM25 for first stage ranking. BERT for query understanding and last re-ranking based on first stage rank   

---
#### DEI-run4 
[**`Results`**](./results.md#dei-run4), [**`Participants`**](./participants.md#iiia-unipd), [**`Proceedings`**](./proceedings.md#question-answering-based-query-expansion-for-conversational-search-iiia-unipd-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.DEI-run4.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run4.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run4.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/DEI-run4.pdf) 

- :material-rename: **Name:** DEI-run4 
- :fontawesome-solid-user-group: **Participant:** iiia-unipd 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/31/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `9de4ef4068185d2a925d65b6b4036fa3` 
- :material-text: **Run description:** NeuralCoref to resolve coreferences, POS tagging based on previous utterances and BERT based QA to carry out query expansion.  BM25 for first stage ranking. BERT for query understanding and last re-ranking based on first stage rank    

---
#### DEI-run5.json 
[**`Results`**](./results.md#dei-run5json), [**`Participants`**](./participants.md#iiia-unipd), [**`Proceedings`**](./proceedings.md#question-answering-based-query-expansion-for-conversational-search-iiia-unipd-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.DEI-run5.json.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run5.json.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.DEI-run5.json.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/DEI-run5.json.pdf) 

- :material-rename: **Name:** DEI-run5.json 
- :fontawesome-solid-user-group: **Participant:** iiia-unipd 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `60772ad21e46e7bdfc32d1f11acd48e5` 
- :material-text: **Run description:** NeuralCoref to resolve coreferences, POS tagging based on previous utterances and BERT based QA to carry out query expansion. LMD for first stage ranking. BERT for query understanding and last re-ranking based on first stage rank     

---
#### duo_reranker 
[**`Results`**](./results.md#duo_reranker), [**`Participants`**](./participants.md#heatwave), [**`Proceedings`**](./proceedings.md#university-of-cambridge-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.duo_reranker.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.duo_reranker.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.duo_reranker.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/duo_reranker.pdf) 

- :material-rename: **Name:** duo_reranker 
- :fontawesome-solid-user-group: **Participant:** HEATWAVE 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `0e845aecfad5caafc6f3c021dce87e11` 
- :material-text: **Run description:** Current and previous utterances are concatenated and used for BM25 (top 3k). expanded query (trained with CANARD) used in monotoT5 reranker. Top 30 passages further reranked using duoT5 answer span extracted using SQuAD2 

---
#### gold 
[**`Results`**](./results.md#gold), [**`Participants`**](./participants.md#heatwave), [**`Proceedings`**](./proceedings.md#university-of-cambridge-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.gold.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.gold.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.gold.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/gold.pdf) 

- :material-rename: **Name:** gold 
- :fontawesome-solid-user-group: **Participant:** HEATWAVE 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `2b67a38cee6c8826c9ea9cf92e2d1f92` 
- :material-text: **Run description:** BM25 used followed by monotoT5 reranker answer span extracted using SQuAD2 

---
#### mi_task_0822_1 
[**`Results`**](./results.md#mi_task_0822_1), [**`Participants`**](./participants.md#udel_fang), [**`Proceedings`**](./proceedings.md#an-exploration-study-of-mixed-initiative-query-reformulation-in-conversational-passage-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.mi_task_0822_1.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.mi_task_0822_1.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.mi_task_0822_1.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/mi_task_0822_1.pdf) 

- :material-rename: **Name:** mi_task_0822_1 
- :fontawesome-solid-user-group: **Participant:** udel_fang 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/22/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** mixed 
- :material-fingerprint: **MD5:** `4e03e39f51d64685cf660021b59718aa` 
- :material-text: **Run description:** a simple rule-based algorithm to generate questions from templates. Basically, there are three types of questions: 1. reference ambiguity clarification question 2. ask for additional descriptive information for an essential noun in the original query. 3. system detected the original query was incomplete and ask the user to complete the query. 

---
#### MLIA_DAC_splade 
[**`Results`**](./results.md#mlia_dac_splade), [**`Participants`**](./participants.md#mlia-dac), [**`Proceedings`**](./proceedings.md#mlia-dac-trec-cast-2022-sparse-contextualized-query-embedding), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.MLIA_DAC_splade.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.MLIA_DAC_splade.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.MLIA_DAC_splade.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/MLIA_DAC_splade.pdf) 

- :material-rename: **Name:** MLIA_DAC_splade 
- :fontawesome-solid-user-group: **Participant:** MLIA-DAC 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/22/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `a113eafc660af563f2e46a1ec59ec419` 
- :material-text: **Run description:** This is an end to end approach. We extend SPLADE, a sparse retrieval model for ad hoc information retrieval, to the conversational use case. We encode the concatenation of queries, and the concatenation of the current query and the previous answer, then aggregate these two embeddings to produce a contextualized query embedding. Matching with document embeddings proceed as in the original SPLADE. 

---
#### monot5 
[**`Results`**](./results.md#monot5), [**`Participants`**](./participants.md#heatwave), [**`Proceedings`**](./proceedings.md#university-of-cambridge-at-trec-cast-2022), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.monot5.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.monot5.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.monot5.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/monot5.pdf) 

- :material-rename: **Name:** monot5 
- :fontawesome-solid-user-group: **Participant:** HEATWAVE 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `6a37b3f5d04405867b3e31c2dfac22c3` 
- :material-text: **Run description:** Current and previous utterances are concatenated and used for BM25. expanded query (trained with QRECC) used in monotoT5 reranker answer span extracted using SQuAD2 

---
#### splade_t5mm 
[**`Results`**](./results.md#splade_t5mm), [**`Participants`**](./participants.md#mlia-dac), [**`Proceedings`**](./proceedings.md#mlia-dac-trec-cast-2022-sparse-contextualized-query-embedding), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.splade_t5mm.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.splade_t5mm.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.splade_t5mm.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/splade_t5mm.pdf) 

- :material-rename: **Name:** splade_t5mm 
- :fontawesome-solid-user-group: **Participant:** MLIA-DAC 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/23/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `811578814d246e0214283a74a349e495` 
- :material-text: **Run description:** We add a reranking step to the run MLIA_DAC_splade. Input is the concatenation of the current query, past queries, 10 keywords identified in the first stage sparse retrieval step, and the passage. We finetune MonoT5 to adapt to this input format, using MSEMargin loss. 

---
#### splade_t5mm_ens 
[**`Results`**](./results.md#splade_t5mm_ens), [**`Participants`**](./participants.md#mlia-dac), [**`Proceedings`**](./proceedings.md#mlia-dac-trec-cast-2022-sparse-contextualized-query-embedding), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.splade_t5mm_ens.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.splade_t5mm_ens.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.splade_t5mm_ens.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/splade_t5mm_ens.pdf) 

- :material-rename: **Name:** splade_t5mm_ens 
- :fontawesome-solid-user-group: **Participant:** MLIA-DAC 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/23/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `7281e0d000912aff259060c3c5f725c6` 
- :material-text: **Run description:** We add a reranking step to the run MLIA_DAC_splade. Input is the concatenation of the current query, past queries, 10 keywords identified in the first stage sparse retrieval step, and the passage. We finetune an ensemble of 4 MonoT5 instances to adapt to this input format, using MSEMargin loss. 

---
#### splade_t5mse 
[**`Results`**](./results.md#splade_t5mse), [**`Participants`**](./participants.md#mlia-dac), [**`Proceedings`**](./proceedings.md#mlia-dac-trec-cast-2022-sparse-contextualized-query-embedding), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.splade_t5mse.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.splade_t5mse.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.splade_t5mse.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/splade_t5mse.pdf) 

- :material-rename: **Name:** splade_t5mse 
- :fontawesome-solid-user-group: **Participant:** MLIA-DAC 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/23/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `dd7afb38523ee7b644a52267216818cd` 
- :material-text: **Run description:** We add a reranking step to the run MLIA_DAC_splade. Input is the concatenation of the current query, past queries, 10 keywords identified in the first stage sparse retrieval step, and the passage. We finetune MonoT5 to adapt to this input format, using Mean Squared Error loss. 

---
#### udinfo_best2021 
[**`Results`**](./results.md#udinfo_best2021), [**`Participants`**](./participants.md#udel_fang), [**`Proceedings`**](./proceedings.md#an-exploration-study-of-mixed-initiative-query-reformulation-in-conversational-passage-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.udinfo_best2021.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_best2021.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_best2021.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/udinfo_best2021.pdf) 

- :material-rename: **Name:** udinfo_best2021 
- :fontawesome-solid-user-group: **Participant:** udel_fang 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `b72cf1b871cb4f3867006b91f8169f95` 
- :material-text: **Run description:** 1st ranking on Bm25 and dense method, then monoT5 and duoT5 for 2nd ranking. Fusion: late_fusion. 

---
#### udinfo_mi_b2021 
[**`Results`**](./results.md#udinfo_mi_b2021), [**`Participants`**](./participants.md#udel_fang), [**`Proceedings`**](./proceedings.md#an-exploration-study-of-mixed-initiative-query-reformulation-in-conversational-passage-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.udinfo_mi_b2021.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_mi_b2021.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_mi_b2021.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/udinfo_mi_b2021.pdf) 

- :material-rename: **Name:** udinfo_mi_b2021 
- :fontawesome-solid-user-group: **Participant:** udel_fang 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic-mi 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `9cba3fed4f4c18c541167f0d1ffbd6ea` 
- :material-text: **Run description:** Perform fusion only on top 4 methods:  1. reranking(monoT5, duoT5) sparse Ntr 2. reranking(monoT5, duoT5) dense Ntr 3. dense Cqe 4. reranking(monoT5) sparse Hqe 

---
#### udinfo_onlyd 
[**`Results`**](./results.md#udinfo_onlyd), [**`Participants`**](./participants.md#udel_fang), [**`Proceedings`**](./proceedings.md#an-exploration-study-of-mixed-initiative-query-reformulation-in-conversational-passage-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.udinfo_onlyd.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_onlyd.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_onlyd.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/udinfo_onlyd.pdf) 

- :material-rename: **Name:** udinfo_onlyd 
- :fontawesome-solid-user-group: **Participant:** udel_fang 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `1763d92be4afdf76d63d789cc34907e1` 
- :material-text: **Run description:** The run aims to compare the first automatic run: If the sparse retrieval is still needed considering dense retrieval to be introduced and tested to be promising in many papers. 

---
#### udinfo_onlyd_mi 
[**`Results`**](./results.md#udinfo_onlyd_mi), [**`Participants`**](./participants.md#udel_fang), [**`Proceedings`**](./proceedings.md#an-exploration-study-of-mixed-initiative-query-reformulation-in-conversational-passage-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.udinfo_onlyd_mi.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_onlyd_mi.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.udinfo_onlyd_mi.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/udinfo_onlyd_mi.pdf) 

- :material-rename: **Name:** udinfo_onlyd_mi 
- :fontawesome-solid-user-group: **Participant:** udel_fang 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic-mi 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `e47bdbf4107ab7d3cb25831430349522` 
- :material-text: **Run description:** 1. The run aims to compare the first automatic run: "If the sparse retrieval is still needed considering dense retrieval to be introduced and tested to be promising in many papers?" 2. The run also aims to compare the performance gap between Ntr(MI) and Ntr(original), to answer the question "If we need MI?" 

---
#### uis_cargoboat 
[**`Results`**](./results.md#uis_cargoboat), [**`Participants`**](./participants.md#uis), [**`Proceedings`**](./proceedings.md#the-university-of-stavanger-iai-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uis_cargoboat.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_cargoboat.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_cargoboat.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uis_cargoboat.pdf) 

- :material-rename: **Name:** uis_cargoboat 
- :fontawesome-solid-user-group: **Participant:** UiS 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `547c949f4c3a5016465459415f69b2a9` 
- :material-text: **Run description:** The first-pass retrieval using BM25 with the parameters tuned on 2020 and 2021 CAsT datasets, is followed by mono T5 reranking and duo T5 reranking, which have been fine-tuned on MS MARCO. The sparse query rewriting is performed with a HuggingFace model fine-tuned on the CANARD dataset on queries pre-processed by an intent classifier. Previously rewritten utterances and the last canonical response are used as a context. The rewritten query is expanded using pseudo-relevance feedback. 

---
#### uis_clearboat 
[**`Results`**](./results.md#uis_clearboat), [**`Participants`**](./participants.md#uis), [**`Proceedings`**](./proceedings.md#the-university-of-stavanger-iai-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uis_clearboat.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_clearboat.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_clearboat.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uis_clearboat.pdf) 

- :material-rename: **Name:** uis_clearboat 
- :fontawesome-solid-user-group: **Participant:** UiS 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/19/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** mixed 
- :material-fingerprint: **MD5:** `879a6b38f1e288acbdc539aca115ea16` 
- :material-text: **Run description:** We first fine-tune RoBERTa to filter out faulty clarifying questions. To this end, we set clarifying questions from ClariQ as a positive class and queries from previous CAsT editions as a negative class. Then, we rank the remaining clarifying questions with MPNet in a pairwise manner given a rewritten query. The rewritten query is generated with T5 fine-tuned on CANARD. 

---
#### uis_duoboat 
[**`Results`**](./results.md#uis_duoboat), [**`Participants`**](./participants.md#uis), [**`Proceedings`**](./proceedings.md#the-university-of-stavanger-iai-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uis_duoboat.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_duoboat.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_duoboat.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uis_duoboat.pdf) 

- :material-rename: **Name:** uis_duoboat 
- :fontawesome-solid-user-group: **Participant:** UiS 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/26/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `73789f6aa3f4c6bd4b13f24690623d69` 
- :material-text: **Run description:** The first-pass retrieval using BM25 with the parameters tuned on 2020 and 2021 CAsT datasets, is followed by mono T5 reranking and duo T5 reranking, which have been fine-tuned on MS MARCO. The query rewriting is performed with a HuggingFace model fine-tuned on the CANARD dataset. Previously rewritten utterances and the last canonical response are used as a context. 

---
#### uis_mixedboat 
[**`Results`**](./results.md#uis_mixedboat), [**`Participants`**](./participants.md#uis), [**`Proceedings`**](./proceedings.md#the-university-of-stavanger-iai-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uis_mixedboat.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_mixedboat.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_mixedboat.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uis_mixedboat.pdf) 

- :material-rename: **Name:** uis_mixedboat 
- :fontawesome-solid-user-group: **Participant:** UiS 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic-mi 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `c7ab8a4f908082388d6eeb9dba74a602` 
- :material-text: **Run description:** We first fine-tune RoBERTa to filter out faulty clarifying questions (based on ClariQ and previous CAsT editions). Then, we rank the remaining clarifying questions with MPNet in a pairwise manner given a query rewritten by T5 fine-tuned on CANARD. We classify answers into three classes: useless, useful answers, and useful questions. The classifier is trained on ClariQ. If the first class is predicted, we do nothing to the original query. If the second or third class is predicted, we append the answer or the question, respectively, to the query. Then, the expanded query is once again rewritten with the T5-based model. The first-pass retrieval using BM25 with the parameters tuned on 2020 and 2021 CAsT datasets with PRF, is followed by mono T5 reranking and duo T5 reranking, which have been fine-tuned on MS MARCO. The query rewriting is performed with a HuggingFace model fine-tuned on the CANARD dataset. Previously rewritten utterances and the last canonical response are used as a context. 

---
#### uis_sparseboat 
[**`Results`**](./results.md#uis_sparseboat), [**`Participants`**](./participants.md#uis), [**`Proceedings`**](./proceedings.md#the-university-of-stavanger-iai-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uis_sparseboat.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_sparseboat.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_sparseboat.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uis_sparseboat.pdf) 

- :material-rename: **Name:** uis_sparseboat 
- :fontawesome-solid-user-group: **Participant:** UiS 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/1/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `8460ac64b11989f8830728951868704a` 
- :material-text: **Run description:** The first-pass retrieval using BM25 with the parameters tuned on 2020 and 2021 CAsT datasets, is followed by mono T5 reranking and duo T5 reranking, which have been fine-tuned on MS MARCO. The sparse query rewriting is performed with a HuggingFace model fine-tuned on the CANARD dataset. Previously rewritten utterances and the last canonical response are used as a context. The rewritten query is expanded using pseudo-relevance feedback. 

---
#### uis_vagueboat 
[**`Results`**](./results.md#uis_vagueboat), [**`Participants`**](./participants.md#uis), [**`Proceedings`**](./proceedings.md#the-university-of-stavanger-iai-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uis_vagueboat.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_vagueboat.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uis_vagueboat.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uis_vagueboat.pdf) 

- :material-rename: **Name:** uis_vagueboat 
- :fontawesome-solid-user-group: **Participant:** UiS 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/19/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** mixed 
- :material-fingerprint: **MD5:** `c026b0d8cae2af8243d9271bd20c6266` 
- :material-text: **Run description:** We first perform query rewriting with T5 fine-tuned on CANARD. Then, we perform retrieval and reranking with BM25+DuoT5, followed by applying transformer-based topic model (top2vec) to extract subtopics in the top 100 documents. Finally, we construct a template-based clarifying question by appending up to three extracted subtopics to a template 'Are you interested in...' or similar. 

---
#### uogTr-AT 
[**`Results`**](./results.md#uogtr-at), [**`Participants`**](./participants.md#uogtr), [**`Proceedings`**](./proceedings.md#university-of-glasgow-terrier-team-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uogTr-AT.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-AT.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-AT.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uogTr-AT.pdf) 

- :material-rename: **Name:** uogTr-AT 
- :fontawesome-solid-user-group: **Participant:** UoGTr 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/6/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `d47aa1ff09d6a1721a3e7b87a39301f0` 
- :material-text: **Run description:** This run uses T5QR trained on CANARD to rewrite user utterances and their context (previous questions + response text). In addition, we leverage a user feedback prediction model trained on CAsT last year to select the context for the T5QR model. For the retriever and reader, we use TCT-ColBERT then rescore and extract an answer by using monoQA. 

---
#### uogTr-MI 
[**`Results`**](./results.md#uogtr-mi), [**`Participants`**](./participants.md#uogtr), [**`Proceedings`**](./proceedings.md#university-of-glasgow-terrier-team-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uogTr-MI.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-MI.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-MI.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uogTr-MI.pdf) 

- :material-rename: **Name:** uogTr-MI 
- :fontawesome-solid-user-group: **Participant:** UoGTr 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/22/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** mixed 
- :material-fingerprint: **MD5:** `ac65f634bfb449fd3f3474500c3befac` 
- :material-text: **Run description:** Our run uses a retrieve + generate models by leveraging the Multi-Task Learning (MTL) T5 model learned to generate the clarification question and select what turns require interaction simultaneously. For the question retrieval, we use py-terrier GTR as the retriever and then use the reranker T5 model to score the retrieved and generated questions. All models are fine-tuned on the ClariQ dataset. 

---
#### uogTr-MI-HB 
[**`Results`**](./results.md#uogtr-mi-hb), [**`Participants`**](./participants.md#uogtr), [**`Proceedings`**](./proceedings.md#university-of-glasgow-terrier-team-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uogTr-MI-HB.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-MI-HB.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-MI-HB.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uogTr-MI-HB.pdf) 

- :material-rename: **Name:** uogTr-MI-HB 
- :fontawesome-solid-user-group: **Participant:** UoGTr 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/6/2022 
- :fontawesome-solid-user-gear: **Type:** automatic-mi 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `915918edb6d7abb10dc507802cc2bc68` 
- :material-text: **Run description:** This run leverage the question-response from MI sub-task as context for our T5QR model for rewriting user utterances. In addition, we leverage a user feedback prediction model trained on CAsT last year to filter out the context with a negative response (MI sub-task) before using it as the context for T5QR. For the retriever and reader,  we use a hybrid retriever (DPH + TCT-ColBERT) and then rescore and extract an answer by using monoQA. 

---
#### uogTr-MT 
[**`Results`**](./results.md#uogtr-mt), [**`Participants`**](./participants.md#uogtr), [**`Proceedings`**](./proceedings.md#university-of-glasgow-terrier-team-at-the-trec-2022-conversational-assistance-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.uogTr-MT.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-MT.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.uogTr-MT.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/uogTr-MT.pdf) 

- :material-rename: **Name:** uogTr-MT 
- :fontawesome-solid-user-group: **Participant:** UoGTr 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/6/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `25aa3f3bdf5aaeaacc9fd236c53bcccf` 
- :material-text: **Run description:** This run uses provided manual rewritten utterances. For the retriever and reader, we use TCT-ColBERT then rescore and extract an answer by using monoQA.  

---
#### UWCauto22 
[**`Results`**](./results.md#uwcauto22), [**`Participants`**](./participants.md#waterlooclarke), [**`Proceedings`**](./proceedings.md#waterlooclarke-at-the-trec-2022-conversational-assistant-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.UWCauto22.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.UWCauto22.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.UWCauto22.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/UWCauto22.pdf) 

- :material-rename: **Name:** UWCauto22 
- :fontawesome-solid-user-group: **Participant:** WaterlooClarke 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/30/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `1afe1aff8f276ee11d99fb1667e04311` 
- :material-text: **Run description:** please find more detail in the notebook paper 

---
#### UWCcano22 
[**`Results`**](./results.md#uwccano22), [**`Participants`**](./participants.md#waterlooclarke), [**`Proceedings`**](./proceedings.md#waterlooclarke-at-the-trec-2022-conversational-assistant-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.UWCcano22.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.UWCcano22.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.UWCcano22.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/UWCcano22.pdf) 

- :material-rename: **Name:** UWCcano22 
- :fontawesome-solid-user-group: **Participant:** WaterlooClarke 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/30/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `f2e0f8edf02361761df3dcffbeb99fc4` 
- :material-text: **Run description:** please find more detail in the notebook paper 

---
#### UWCmanual22 
[**`Results`**](./results.md#uwcmanual22), [**`Participants`**](./participants.md#waterlooclarke), [**`Proceedings`**](./proceedings.md#waterlooclarke-at-the-trec-2022-conversational-assistant-track), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.UWCmanual22.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.UWCmanual22.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.UWCmanual22.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/UWCmanual22.pdf) 

- :material-rename: **Name:** UWCmanual22 
- :fontawesome-solid-user-group: **Participant:** WaterlooClarke 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 8/30/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `4060448b9e09c0d1e40828d7ba72183c` 
- :material-text: **Run description:** manual run using manual rewritten utterances. 

---
#### V-Ryerson-run 
[**`Results`**](./results.md#v-ryerson-run), [**`Participants`**](./participants.md#v-ryerson), [**`Input`**](https://trec.nist.gov/results/trec31/cast/input.V-Ryerson-run.gz), [**`Summary (strict)`**](https://trec.nist.gov/results/trec31/cast/summary.V-Ryerson-run.strict), [**`Summary (lenient)`**](https://trec.nist.gov/results/trec31/cast/summary.V-Ryerson-run.lenient), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/cast/V-Ryerson-run.pdf) 

- :material-rename: **Name:** V-Ryerson-run 
- :fontawesome-solid-user-group: **Participant:** V-Ryerson 
- :material-format-text: **Track:** Conversational Assistance 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 9/4/2022 
- :fontawesome-solid-user-gear: **Type:** automatic 
- :material-text-search: **Task:** primary 
- :material-fingerprint: **MD5:** `9e58f5562597f96665b51e77f254368e` 
- :material-text: **Run description:** Pre-trained Neural Language model Roberta-large is used for ranking. 

---
