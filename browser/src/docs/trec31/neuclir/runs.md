# Runs - NeuCLIR 2022 

#### CFDA_CLIP_dq 
[**`Results`**](./results.md#cfda_clip_dq), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_dq.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_dq.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_dq.pdf) 

- :material-rename: **Name:** CFDA_CLIP_dq 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `79f8c15cd852e6e20c1c243f7b030384` 
- :material-text: **Run description:** query translation, monot5 with dual query reranking. 

---
#### CFDA_CLIP_fas_clf 
[**`Results`**](./results.md#cfda_clip_fas_clf), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_fas_clf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_fas_clf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_fas_clf.pdf) 

- :material-rename: **Name:** CFDA_CLIP_fas_clf 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `7c043f32a810b1e59efe9290212e06b4` 
- :material-text: **Run description:** sparse retrieval, query translation, crosslingual fine-tuned reranker 

---
#### CFDA_CLIP_fas_L 
[**`Results`**](./results.md#cfda_clip_fas_l), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_fas_L.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_fas_L.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_fas_L.pdf) 

- :material-rename: **Name:** CFDA_CLIP_fas_L 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `a3351448a8dc1b21a16b90f547cc9682` 
- :material-text: **Run description:** query translation, sparse retrieval, t5 large reranking  

---
#### CFDA_CLIP_rus_clf 
[**`Results`**](./results.md#cfda_clip_rus_clf), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_rus_clf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_rus_clf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_rus_clf.pdf) 

- :material-rename: **Name:** CFDA_CLIP_rus_clf 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `2c57b98cc9fcf111d523a5cf03af8768` 
- :material-text: **Run description:** sparse retrieval, query translation, crosslingual fine-tuned reranker 

---
#### CFDA_CLIP_rus_dq 
[**`Results`**](./results.md#cfda_clip_rus_dq), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_rus_dq.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_rus_dq.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_rus_dq.pdf) 

- :material-rename: **Name:** CFDA_CLIP_rus_dq 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `a3873cc1ec2cfcef4a8dd7ce77069f0f` 
- :material-text: **Run description:** sparse retrieval, query translation, reranking with dual query 

---
#### CFDA_CLIP_rus_L 
[**`Results`**](./results.md#cfda_clip_rus_l), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_rus_L.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_rus_L.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_rus_L.pdf) 

- :material-rename: **Name:** CFDA_CLIP_rus_L 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `cc9de1495f2fbac49937ced28e16f62b` 
- :material-text: **Run description:** query translation, sparse retrieval, t5 large ranker 

---
#### CFDA_CLIP_zho_clf 
[**`Results`**](./results.md#cfda_clip_zho_clf), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_zho_clf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_zho_clf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_zho_clf.pdf) 

- :material-rename: **Name:** CFDA_CLIP_zho_clf 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `7016abbbfc3f5ddbc473a443bd0af7a1` 
- :material-text: **Run description:** sparse retrieval, query translation, crosslingual fine-tuned reranker 

---
#### CFDA_CLIP_zho_dq 
[**`Results`**](./results.md#cfda_clip_zho_dq), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_zho_dq.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_zho_dq.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_zho_dq.pdf) 

- :material-rename: **Name:** CFDA_CLIP_zho_dq 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `8cf04582800d30030774c4944dd4a72c` 
- :material-text: **Run description:** sparse retrieval, query translation, reranking with dual query 

---
#### CFDA_CLIP_zho_L 
[**`Results`**](./results.md#cfda_clip_zho_l), [**`Participants`**](./participants.md#cfda_clip), [**`Proceedings`**](./proceedings.md#cfda-clip-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.CFDA_CLIP_zho_L.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.CFDA_CLIP_zho_L.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/CFDA_CLIP_zho_L.pdf) 

- :material-rename: **Name:** CFDA_CLIP_zho_L 
- :fontawesome-solid-user-group: **Participant:** CFDA_CLIP 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `f33fe29faa2221acc2723e8dbd1aa649` 
- :material-text: **Run description:** sparse retrieval, query translation, T5 large reranking 

---
#### coe22-bm25-d-dt-fas 
[**`Results`**](./results.md#coe22-bm25-d-dt-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-dt-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-dt-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-dt-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-d-dt-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `5a46e279f1c9f9cabac110543c7d2e4d` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the descriptions written in English. Default values were used for both BM25 and RM3. Spacey was used for tokenization and stemming. 

---
#### coe22-bm25-d-dt-rus 
[**`Results`**](./results.md#coe22-bm25-d-dt-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-dt-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-dt-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-dt-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-d-dt-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `f58e1eff406db059d8888ae11ca015cf` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the descriptions written in English. Default values were used for both BM25 and RM3. Spacey was used for tokenization and stemming. 

---
#### coe22-bm25-d-dt-zho 
[**`Results`**](./results.md#coe22-bm25-d-dt-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-dt-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-dt-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-dt-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-d-dt-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `b6af9db407853d5730fdb8270cc6e14c` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the descriptions written in English. Default values were used for both BM25 and RM3. Spacey was used for tokenization and stemming. 

---
#### coe22-bm25-d-ht-fas 
[**`Results`**](./results.md#coe22-bm25-d-ht-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-ht-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-ht-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-ht-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-d-ht-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `3c7a58db3e49b0a18275f22865e2df93` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized with spacey and stemmed with parsivar.  

---
#### coe22-bm25-d-ht-rus 
[**`Results`**](./results.md#coe22-bm25-d-ht-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-ht-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-ht-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-ht-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-d-ht-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `8306058a2f6fd074ebf2044ee80730dd` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized and stemmed with spacey.  

---
#### coe22-bm25-d-ht-zho 
[**`Results`**](./results.md#coe22-bm25-d-ht-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-ht-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-ht-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-ht-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-d-ht-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `4749f2bcdb6ab7d8c84760643a20b161` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized with spacey.  

---
#### coe22-bm25-d-mt-fas 
[**`Results`**](./results.md#coe22-bm25-d-mt-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-mt-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-mt-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-mt-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-d-mt-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `9a29045884b78273197882db2a4796dc` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized with spacey and stemmed with parsivar.  

---
#### coe22-bm25-d-mt-rus 
[**`Results`**](./results.md#coe22-bm25-d-mt-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-mt-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-mt-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-mt-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-d-mt-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `4fde2b708fe275222729967aad2c7d09` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized and stemmed with spacey.  

---
#### coe22-bm25-d-mt-zho 
[**`Results`**](./results.md#coe22-bm25-d-mt-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-d-mt-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-d-mt-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-d-mt-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-d-mt-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `641d11a1bbdb44e65913572c3f9e411d` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized with spacey.  

---
#### coe22-bm25-t-dt-fas 
[**`Results`**](./results.md#coe22-bm25-t-dt-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-dt-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-dt-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-dt-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-t-dt-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `5cfef65213a464e58ed43df8f24fdf53` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the titles written in English as queries. Default values were used for both BM25 and RM3. Spacey was used for tokenization and stemming. 

---
#### coe22-bm25-t-dt-rus 
[**`Results`**](./results.md#coe22-bm25-t-dt-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-dt-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-dt-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-dt-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-t-dt-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `71244665b17a985740828b09b5ef56a9` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the titles written in English as queries. Default values were used for both BM25 and RM3. Spacey was used for tokenization and stemming. 

---
#### coe22-bm25-t-dt-zho 
[**`Results`**](./results.md#coe22-bm25-t-dt-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-dt-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-dt-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-dt-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-t-dt-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `4feaf86a83fce222d17a699e54161b66` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the titles written in English as queries. Default values were used for both BM25 and RM3. Spacey was used for tokenization and stemming. 

---
#### coe22-bm25-t-ht-rus 
[**`Results`**](./results.md#coe22-bm25-t-ht-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-ht-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-ht-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-ht-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-t-ht-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `9999fad6c0ca37dae5b0ca37e8ae0a8a` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized and stemmed with spacey. 

---
#### coe22-bm25-t-ht-zho 
[**`Results`**](./results.md#coe22-bm25-t-ht-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-ht-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-ht-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-ht-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-t-ht-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `982f5ba7d5f015e43767108dd94b78e3` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized with spacey. 

---
#### coe22-bm25-t-mt-fas 
[**`Results`**](./results.md#coe22-bm25-t-mt-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-mt-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-mt-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-mt-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-t-mt-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `557148fca161e97914f007ab7f01f0ee` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized with spacey and stemmed with parsivar.  

---
#### coe22-bm25-t-mt-rus 
[**`Results`**](./results.md#coe22-bm25-t-mt-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-mt-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-mt-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-mt-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-t-mt-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `297b4ce6f11419a6cbef47eb5d29d907` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized and stemmed with spacey.  

---
#### coe22-bm25-t-mt-zho 
[**`Results`**](./results.md#coe22-bm25-t-mt-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-t-mt-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-t-mt-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-t-mt-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-t-mt-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `0aef26ba6ef4575c27049c50dfe5448b` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized with spacey. Topic 128 retrieves no documents.  

---
#### coe22-bm25-td-dt-fas 
[**`Results`**](./results.md#coe22-bm25-td-dt-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-dt-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-dt-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-dt-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-td-dt-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `554e4519f30f0526a6aa120d62738f57` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the titles and descriptions written in English. This is the track provided baseline run. 

---
#### coe22-bm25-td-dt-rus 
[**`Results`**](./results.md#coe22-bm25-td-dt-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-dt-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-dt-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-dt-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-td-dt-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `3ea5866dad44efd5d4809e72ecc94e08` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the titles and descriptions written in English. This is the track provided baseline run. 

---
#### coe22-bm25-td-dt-zho 
[**`Results`**](./results.md#coe22-bm25-td-dt-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-dt-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-dt-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-dt-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-td-dt-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `ae24a8f32d13e81de9f3a403c403fdc5` 
- :material-text: **Run description:** English sparse retrieval was performed with BM25+RM3 with the titles and descriptions written in English. This is the track provided baseline run. 

---
#### coe22-bm25-td-ht-fas 
[**`Results`**](./results.md#coe22-bm25-td-ht-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-ht-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-ht-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-ht-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-td-ht-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `1eca72902c565fe92b591a4366d116ce` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized with spacey and stemmed with parsivar.  

---
#### coe22-bm25-td-ht-rus 
[**`Results`**](./results.md#coe22-bm25-td-ht-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-ht-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-ht-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-ht-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-td-ht-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `0d44be39d68505b9681f675439d7479f` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized and stemmed with spacey. 

---
#### coe22-bm25-td-ht-zho 
[**`Results`**](./results.md#coe22-bm25-td-ht-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-ht-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-ht-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-ht-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-td-ht-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `07f6b701d573d0d8e162ad4e8c0ad013` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/human queries were with tokenized with spacey.  

---
#### coe22-bm25-td-mt-fas 
[**`Results`**](./results.md#coe22-bm25-td-mt-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-mt-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-mt-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-mt-fas.pdf) 

- :material-rename: **Name:** coe22-bm25-td-mt-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `59ad900812170592f590d1fa975f6bca` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized with spacey and stemmed with parsivar.  

---
#### coe22-bm25-td-mt-rus 
[**`Results`**](./results.md#coe22-bm25-td-mt-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-mt-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-mt-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-mt-rus.pdf) 

- :material-rename: **Name:** coe22-bm25-td-mt-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `fb830ffcac9399fc3fa810ba96d3b70c` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized and stemmed with spacey.  

---
#### coe22-bm25-td-mt-zho 
[**`Results`**](./results.md#coe22-bm25-td-mt-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-bm25-td-mt-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-bm25-td-mt-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-bm25-td-mt-zho.pdf) 

- :material-rename: **Name:** coe22-bm25-td-mt-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `ecef2f58bcc5d7062037d4e0f5cd3b1c` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/machine translated queries were with tokenized with spacey.  

---
#### coe22-man-fas 
[**`Results`**](./results.md#coe22-man-fas), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-man-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-man-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-man-fas.pdf) 

- :material-rename: **Name:** coe22-man-fas 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `493ae978188cb0a031fe504738887c0b` 
- :material-text: **Run description:** Monolingual sparse retrieval was performed with BM25. Top ranked documents were ones the annotator marked a relevant. If annotators identified at least one relevant document, they could use HiCAL to recommend more documents to judge. Lists were augmented with unexamined documents using a weighted round robin approach based on the number of relevant documents the annotator discovered with that query. 

---
#### coe22-man-rus 
[**`Results`**](./results.md#coe22-man-rus), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-man-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-man-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-man-rus.pdf) 

- :material-rename: **Name:** coe22-man-rus 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `ed758ff25ee0892cf012cf67ba3842f6` 
- :material-text: **Run description:** Monolingual sparse retrieval was performed with BM25. Top ranked documents were ones the annotator marked a relevant. If annotators identified at least one relevant document, they could use HiCAL to recommend more documents to judge. Lists were augmented with unexamined documents using a weighted round robin approach based on the number of relevant documents the annotator discovered with that query. 

---
#### coe22-man-zho 
[**`Results`**](./results.md#coe22-man-zho), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-man-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-man-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-man-zho.pdf) 

- :material-rename: **Name:** coe22-man-zho 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `340c127b6479b1c1c985df816bd106d9` 
- :material-text: **Run description:** Monolingual sparse retrieval was performed with BM25. Top ranked documents were ones the annotator marked a relevant. If annotators identified at least one relevant document, they could use HiCAL to recommend more documents to judge. Lists were augmented with unexamined documents using a weighted round robin approach based on the number of relevant documents the annotator discovered with that query. 

---
#### coe22-mhq-fas_colxtt 
[**`Results`**](./results.md#coe22-mhq-fas_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-mhq-fas_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-mhq-fas_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-mhq-fas_colxtt.pdf) 

- :material-rename: **Name:** coe22-mhq-fas_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `c79f82f0ef7049d9d4a421ab5ce62eb5` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using manually created queries by the COE annotators. If multiple queries in the original manual search bring up relevant documents, the rank lists using those queries are fused based.  

---
#### coe22-mhq-rus_colxtt 
[**`Results`**](./results.md#coe22-mhq-rus_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-mhq-rus_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-mhq-rus_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-mhq-rus_colxtt.pdf) 

- :material-rename: **Name:** coe22-mhq-rus_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `ebf684a56c1f869c04704fea242c25ea` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using manually created queries by the COE annotators. If multiple queries in the original manual search bring up relevant documents, the rank lists using those queries are fused based.  

---
#### coe22-mhq-zho_colxtt 
[**`Results`**](./results.md#coe22-mhq-zho_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-mhq-zho_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-mhq-zho_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-mhq-zho_colxtt.pdf) 

- :material-rename: **Name:** coe22-mhq-zho_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `1504f4714ad302f9eb12d0f27befe9bb` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using manually created queries by the COE annotators. If multiple queries in the original manual search bring up relevant documents, the rank lists using those queries are fused based.  

---
#### coe22-tdq-fas_colxmtt 
[**`Results`**](./results.md#coe22-tdq-fas_colxmtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tdq-fas_colxmtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tdq-fas_colxmtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tdq-fas_colxmtt.pdf) 

- :material-rename: **Name:** coe22-tdq-fas_colxmtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `68c107ed2ded3750dfd9f0bae74e980d` 
- :material-text: **Run description:** ColBERT-X with multilingual translate-train that searches using title+description queries.  

---
#### coe22-tdq-fas_colxtt 
[**`Results`**](./results.md#coe22-tdq-fas_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tdq-fas_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tdq-fas_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tdq-fas_colxtt.pdf) 

- :material-rename: **Name:** coe22-tdq-fas_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `1eef6146af4026f59ffeb35e2605f869` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using title+description queries.  

---
#### coe22-tdq-rus_colxmtt 
[**`Results`**](./results.md#coe22-tdq-rus_colxmtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tdq-rus_colxmtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tdq-rus_colxmtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tdq-rus_colxmtt.pdf) 

- :material-rename: **Name:** coe22-tdq-rus_colxmtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `57a1c7379a243b7253fbd79c3a10859a` 
- :material-text: **Run description:** ColBERT-X with multilingual translate-train that searches using title+description queries.  

---
#### coe22-tdq-rus_colxtt 
[**`Results`**](./results.md#coe22-tdq-rus_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tdq-rus_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tdq-rus_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tdq-rus_colxtt.pdf) 

- :material-rename: **Name:** coe22-tdq-rus_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `7ff89dfca1b00a31f9850f87128f6897` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using title+description queries.  

---
#### coe22-tdq-zho_colxmtt 
[**`Results`**](./results.md#coe22-tdq-zho_colxmtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tdq-zho_colxmtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tdq-zho_colxmtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tdq-zho_colxmtt.pdf) 

- :material-rename: **Name:** coe22-tdq-zho_colxmtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `bfc2aec76626b5fec3af1bc89bf77747` 
- :material-text: **Run description:** ColBERT-X with multilingual translate-train that searches using title+description queries.  

---
#### coe22-tdq-zho_colxtt 
[**`Results`**](./results.md#coe22-tdq-zho_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tdq-zho_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tdq-zho_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tdq-zho_colxtt.pdf) 

- :material-rename: **Name:** coe22-tdq-zho_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `668dc9c8d21e1d74e1e9491a637f0fbf` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using title+description queries.  

---
#### coe22-tq-fas_colxmtt 
[**`Results`**](./results.md#coe22-tq-fas_colxmtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tq-fas_colxmtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tq-fas_colxmtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tq-fas_colxmtt.pdf) 

- :material-rename: **Name:** coe22-tq-fas_colxmtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `b24e93afb5646b7ddd8530b8b3304443` 
- :material-text: **Run description:** ColBERT-X with multilingual translate-train that searches using title queries.  

---
#### coe22-tq-fas_colxtt 
[**`Results`**](./results.md#coe22-tq-fas_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tq-fas_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tq-fas_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tq-fas_colxtt.pdf) 

- :material-rename: **Name:** coe22-tq-fas_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `e8d939274928dd2ed5007074578b6481` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using title queries.  

---
#### coe22-tq-rus_colxmtt 
[**`Results`**](./results.md#coe22-tq-rus_colxmtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tq-rus_colxmtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tq-rus_colxmtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tq-rus_colxmtt.pdf) 

- :material-rename: **Name:** coe22-tq-rus_colxmtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `70859436e8c823e458449f8dc52150dd` 
- :material-text: **Run description:** ColBERT-X with multilingual translate-train that searches using title queries.  

---
#### coe22-tq-rus_colxtt 
[**`Results`**](./results.md#coe22-tq-rus_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tq-rus_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tq-rus_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tq-rus_colxtt.pdf) 

- :material-rename: **Name:** coe22-tq-rus_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `f2ab35eaa138da9e1a2cb7b6ea79fe01` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using title queries.  

---
#### coe22-tq-zho_colxmtt 
[**`Results`**](./results.md#coe22-tq-zho_colxmtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tq-zho_colxmtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tq-zho_colxmtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tq-zho_colxmtt.pdf) 

- :material-rename: **Name:** coe22-tq-zho_colxmtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `f2232afc3af6ef6f4653e86165d80fc5` 
- :material-text: **Run description:** ColBERT-X with multilingual translate-train that searches using title queries.  

---
#### coe22-tq-zho_colxtt 
[**`Results`**](./results.md#coe22-tq-zho_colxtt), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.coe22-tq-zho_colxtt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.coe22-tq-zho_colxtt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/coe22-tq-zho_colxtt.pdf) 

- :material-rename: **Name:** coe22-tq-zho_colxtt 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `365beaf27650f40e5e7921d7b53e9c37` 
- :material-text: **Run description:** ColBERT-X with translate-train that searches using title queries.  

---
#### F4-PyTerrierPL2 
[**`Results`**](./results.md#f4-pyterrierpl2), [**`Participants`**](./participants.md#f4), [**`Proceedings`**](./proceedings.md#hnust-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.F4-PyTerrierPL2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.F4-PyTerrierPL2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/F4-PyTerrierPL2.pdf) 

- :material-rename: **Name:** F4-PyTerrierPL2 
- :fontawesome-solid-user-group: **Participant:** F4 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `fb6c47ec31b434d0c38236e783c4e975` 
- :material-text: **Run description:** A traditional information retrieval method. After some pre-processing of the topics and documents data, the search results are generated using the integrated weighting model "PL2" on the PyTerrier platform. 

---
#### F4-PyTerrierPL2-ru 
[**`Results`**](./results.md#f4-pyterrierpl2-ru), [**`Participants`**](./participants.md#f4), [**`Proceedings`**](./proceedings.md#hnust-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.F4-PyTerrierPL2-ru.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.F4-PyTerrierPL2-ru.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/F4-PyTerrierPL2-ru.pdf) 

- :material-rename: **Name:** F4-PyTerrierPL2-ru 
- :fontawesome-solid-user-group: **Participant:** F4 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `9866d82e51bdd9966e2ba5e8f7f47883` 
- :material-text: **Run description:** A traditional information retrieval method. After some pre-processing of the Topics and Documents data, the search results are generated using the integrated weighting model "PL2" on the PyTerrier platform. 

---
#### F4-PyTerrierPL2-zh 
[**`Results`**](./results.md#f4-pyterrierpl2-zh), [**`Participants`**](./participants.md#f4), [**`Proceedings`**](./proceedings.md#hnust-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.F4-PyTerrierPL2-zh.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.F4-PyTerrierPL2-zh.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/F4-PyTerrierPL2-zh.pdf) 

- :material-rename: **Name:** F4-PyTerrierPL2-zh 
- :fontawesome-solid-user-group: **Participant:** F4 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `2f3d528d34f55d5ff0e76efe27f70d8a` 
- :material-text: **Run description:** A traditional information retrieval method. After some pre-processing of the Topics and Documents data, the search results are generated using the integrated weighting model "PL2" on the PyTerrier platform. 

---
#### fa_2t 
[**`Results`**](./results.md#fa_2t), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_2t.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_2t.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_2t.pdf) 

- :material-rename: **Name:** fa_2t 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `fc5fd503639f43666233f1f7573a081d` 
- :material-text: **Run description:** Sparse BM25 

---
#### fa_2tr 
[**`Results`**](./results.md#fa_2tr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_2tr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_2tr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_2tr.pdf) 

- :material-rename: **Name:** fa_2tr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `abb0fb13f523ae8a98448a144644e531` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### fa_3rrf 
[**`Results`**](./results.md#fa_3rrf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_3rrf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_3rrf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_3rrf.pdf) 

- :material-rename: **Name:** fa_3rrf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `82c5aebf46fbfd43780884f2eba4389c` 
- :material-text: **Run description:** Sparse BM25 

---
#### fa_3rrf2 
[**`Results`**](./results.md#fa_3rrf2), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_3rrf2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_3rrf2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_3rrf2.pdf) 

- :material-rename: **Name:** fa_3rrf2 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `7723c71113c8ad8d9d10f596f5535145` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### fa_3rrfprf 
[**`Results`**](./results.md#fa_3rrfprf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_3rrfprf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_3rrfprf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_3rrfprf.pdf) 

- :material-rename: **Name:** fa_3rrfprf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `165a09fb665c8681ba2e4e773956528d` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### fa_dense-rrf.BM25.SPLADE 
[**`Results`**](./results.md#fa_dense-rrfbm25splade), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_dense-rrf.BM25.SPLADE.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_dense-rrf.BM25.SPLADE.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_dense-rrf.BM25.SPLADE.pdf) 

- :material-rename: **Name:** fa_dense-rrf.BM25.SPLADE 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `75cd64258ef7143642bab42e315e2914` 
- :material-text: **Run description:**     For Fa:          We RRF the runfiles of tags: dense-rrf.prf, BM25 Baseline run fa_3rrfprf and SPLADE run rocchio.fa.official_ht.dt, keeping the top1k.     For Ru:         We RRF the runfiles of tags: dense-rrf.prf, BM25 Baseline run ru_2rrfprf and SPLADE run rocchio.ru.official_ht.dt, keeping the top1k.     For Zh:         We RRF the runfiles of tags: dense-rrf.prf and BM25 Baseline run zh_4rrfprf, keeping the top1k. 

---
#### fa_dense-rrf.prf 
[**`Results`**](./results.md#fa_dense-rrfprf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_dense-rrf.prf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_dense-rrf.prf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_dense-rrf.prf.pdf) 

- :material-rename: **Name:** fa_dense-rrf.prf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `d0cc79f1bc2bf68e50ce59196ed70c9a` 
- :material-text: **Run description:**     We RRF the runfiles of tags: xdpr.msmarco.official_ht.d.prf, xdpr.xor-hn-mmarco.EN-q.d.prf, xdpr.msmarco.2rrf-mt-q.all.prf and keep the top1k. 

---
#### fa_dt 
[**`Results`**](./results.md#fa_dt), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_dt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_dt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_dt.pdf) 

- :material-rename: **Name:** fa_dt 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `d657190e39bcbd8bd1cf6d07f9d0e75c` 
- :material-text: **Run description:** Sparse BM25 

---
#### fa_dtr 
[**`Results`**](./results.md#fa_dtr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_dtr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_dtr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_dtr.pdf) 

- :material-rename: **Name:** fa_dtr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `6e4936f689fdf6e79e80fea4963577d5` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### fa_qt 
[**`Results`**](./results.md#fa_qt), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_qt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_qt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_qt.pdf) 

- :material-rename: **Name:** fa_qt 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `6c33cc91828b9145981aebae84245193` 
- :material-text: **Run description:** Sparse BM25 

---
#### fa_qtr 
[**`Results`**](./results.md#fa_qtr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_qtr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_qtr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_qtr.pdf) 

- :material-rename: **Name:** fa_qtr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `54da87d62891fe5bca6e2bc39a76ffdf` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### fa_xdpr.mm.2rrf-mtQ.all.R 
[**`Results`**](./results.md#fa_xdprmm2rrf-mtqallr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_xdpr.mm.2rrf-mtQ.all.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_xdpr.mm.2rrf-mtQ.all.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_xdpr.mm.2rrf-mtQ.all.R.pdf) 

- :material-rename: **Name:** fa_xdpr.mm.2rrf-mtQ.all.R 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `b849f661904b3d28f8fe85e3f3615872` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R and fine-tuned on MS MARCO dataset for 40 epoch.     The model then is applied on the NeuCLIR dataset in a zero-shot mannar. No sparse model is involved.     In the inference we obtain {2,4} different runfiles using different version of translated queries, then RRF all runfiles and keep the top1k.     We used Rocchio provided by Pyserini (config:  --prf-depth 5 --rocchio-topk 5  --rocchio-alpha 0.4  --rocchio-beta 0.6)  

---
#### fa_xdpr.ms.oht.d.R 
[**`Results`**](./results.md#fa_xdprmsohtdr), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_xdpr.ms.oht.d.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_xdpr.ms.oht.d.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_xdpr.ms.oht.d.R.pdf) 

- :material-rename: **Name:** fa_xdpr.ms.oht.d.R 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `116a1c331c0c34560a0c135a9503456f` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R and fine-tuned on MS MARCO dataset for 40 epoch.     The model then is applied on the NeuCLIR dataset in a zero-shot mannar. No sparse model is involved.     We used Rocchio provided by Pyserini (config:  --prf-depth 5 --rocchio-topk 5  --rocchio-alpha 0.4  --rocchio-beta 0.6)  

---
#### fa_xdpr.xorHn-mm.EN.d.R 
[**`Results`**](./results.md#fa_xdprxorhn-mmendr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.fa_xdpr.xorHn-mm.EN.d.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.fa_xdpr.xorHn-mm.EN.d.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/fa_xdpr.xorHn-mm.EN.d.R.pdf) 

- :material-rename: **Name:** fa_xdpr.xorHn-mm.EN.d.R 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `9810acbe031970d2cde183b2b3782443` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R.     The model is firstly trained on XOR-TyDi data, involving all languages, then fine-tuned on mMARCO dataset.     We use the offical small training set of mMARCO, but we map the query id and document id into different languages, e.g., query in Chinese and Document in English.      Note that we use all the languages in mMARCO, so the query and document might involve languages that's not in target language or English (e.g. Arabic)     The model then is applied on the NeuCLIR dataset in a zero-shot mannar, where the relevance score is directly matched between English queries and target documents.     No sparse model is involved. 

---
#### hltcoe22tht 
[**`Results`**](./results.md#hltcoe22tht), [**`Participants`**](./participants.md#hltcoe-jhu), [**`Proceedings`**](./proceedings.md#hltcoe-at-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.hltcoe22tht.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.hltcoe22tht.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/hltcoe22tht.pdf) 

- :material-rename: **Name:** hltcoe22tht 
- :fontawesome-solid-user-group: **Participant:** hltcoe-jhu 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/22/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `879f2f49b44f8de4edf69aa44faae517` 
- :material-text: **Run description:** Sparse retrieval with BM25 with default settings and RM3 with default settings. Documents/Queries were with tokenized with spacey and stemmed with parsivar.  

---
#### huaweimtl-fa-c-hybrid2 
[**`Results`**](./results.md#huaweimtl-fa-c-hybrid2), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-fa-c-hybrid2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-fa-c-hybrid2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-fa-c-hybrid2.pdf) 

- :material-rename: **Name:** huaweimtl-fa-c-hybrid2 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `1452b8343664a3fa4b85dfe10777b380` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval and several sparse models 

---
#### huaweimtl-fa-c-hybrid3 
[**`Results`**](./results.md#huaweimtl-fa-c-hybrid3), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-fa-c-hybrid3.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-fa-c-hybrid3.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-fa-c-hybrid3.pdf) 

- :material-rename: **Name:** huaweimtl-fa-c-hybrid3 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `155874b726146f7e337b0564acd2b8a8` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval with several sparse models 

---
#### huaweimtl-fa-m-hybrid1 
[**`Results`**](./results.md#huaweimtl-fa-m-hybrid1), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-fa-m-hybrid1.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-fa-m-hybrid1.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-fa-m-hybrid1.pdf) 

- :material-rename: **Name:** huaweimtl-fa-m-hybrid1 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `2618f4af0f17d88399e546053b0c0f61` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval and several sparse models 

---
#### huaweimtl-ru-c-hybrid2 
[**`Results`**](./results.md#huaweimtl-ru-c-hybrid2), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-ru-c-hybrid2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-ru-c-hybrid2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-ru-c-hybrid2.pdf) 

- :material-rename: **Name:** huaweimtl-ru-c-hybrid2 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `d36bb1138b685aa510f253ecd9ff6c07` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval with several sparse models 

---
#### huaweimtl-ru-c-hybrid3 
[**`Results`**](./results.md#huaweimtl-ru-c-hybrid3), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-ru-c-hybrid3.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-ru-c-hybrid3.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-ru-c-hybrid3.pdf) 

- :material-rename: **Name:** huaweimtl-ru-c-hybrid3 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `c8534be4b716bf7b3edb6d06c4c8bd06` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval with several sparse models 

---
#### huaweimtl-ru-m-hybrid1 
[**`Results`**](./results.md#huaweimtl-ru-m-hybrid1), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-ru-m-hybrid1.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-ru-m-hybrid1.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-ru-m-hybrid1.pdf) 

- :material-rename: **Name:** huaweimtl-ru-m-hybrid1 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `3aaf0c2ba505195193ddad328047abc8` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval with several sparse models 

---
#### huaweimtl-zh-c-hybrid2 
[**`Results`**](./results.md#huaweimtl-zh-c-hybrid2), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-zh-c-hybrid2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-zh-c-hybrid2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-zh-c-hybrid2.pdf) 

- :material-rename: **Name:** huaweimtl-zh-c-hybrid2 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `b8b134babb43b4ab6c921561635a6d95` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval with several sparse models 

---
#### huaweimtl-zh-c-hybrid3 
[**`Results`**](./results.md#huaweimtl-zh-c-hybrid3), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-zh-c-hybrid3.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-zh-c-hybrid3.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-zh-c-hybrid3.pdf) 

- :material-rename: **Name:** huaweimtl-zh-c-hybrid3 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `21b70594d063f85a51dd0421955f8698` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval with several sparse models 

---
#### huaweimtl-zh-m-hybrid1 
[**`Results`**](./results.md#huaweimtl-zh-m-hybrid1), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.huaweimtl-zh-m-hybrid1.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.huaweimtl-zh-m-hybrid1.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/huaweimtl-zh-m-hybrid1.pdf) 

- :material-rename: **Name:** huaweimtl-zh-m-hybrid1 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `de1b10b0618da9697461b0837e7269bd` 
- :material-text: **Run description:** Hybrid model that combines dense retrieval with several sparse models 

---
#### IDACCS-baseline 
[**`Results`**](./results.md#idaccs-baseline), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-baseline.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-baseline.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-baseline.pdf) 

- :material-rename: **Name:** IDACCS-baseline 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `c7aa37f832ae41a62a2f680f0c588634` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-baseline_raranking 
[**`Results`**](./results.md#idaccs-baseline_raranking), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-baseline_raranking.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-baseline_raranking.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-baseline_raranking.pdf) 

- :material-rename: **Name:** IDACCS-baseline_raranking 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `10691abb9600c2e14865ae501b521a37` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-baseline_rrank_rus 
[**`Results`**](./results.md#idaccs-baseline_rrank_rus), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-baseline_rrank_rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-baseline_rrank_rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-baseline_rrank_rus.pdf) 

- :material-rename: **Name:** IDACCS-baseline_rrank_rus 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `295a7def807ad026323e36e9b4f4522d` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-baseline_rrank_zho 
[**`Results`**](./results.md#idaccs-baseline_rrank_zho), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-baseline_rrank_zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-baseline_rrank_zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-baseline_rrank_zho.pdf) 

- :material-rename: **Name:** IDACCS-baseline_rrank_zho 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `e64a5881112de2dd5542c7751e8ec9e2` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-baseline_rus 
[**`Results`**](./results.md#idaccs-baseline_rus), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-baseline_rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-baseline_rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-baseline_rus.pdf) 

- :material-rename: **Name:** IDACCS-baseline_rus 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `170aeadcd78f586b90fe9b42e70677cf` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-baseline_zho 
[**`Results`**](./results.md#idaccs-baseline_zho), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-baseline_zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-baseline_zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-baseline_zho.pdf) 

- :material-rename: **Name:** IDACCS-baseline_zho 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `a3ce95842fff14c157587da8016aefb0` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-run1 
[**`Results`**](./results.md#idaccs-run1), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run1.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run1.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run1.pdf) 

- :material-rename: **Name:** IDACCS-run1 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `80d687f53f1b2dfd09a15e3c9f641826` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-run1_reranking 
[**`Results`**](./results.md#idaccs-run1_reranking), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run1_reranking.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run1_reranking.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run1_reranking.pdf) 

- :material-rename: **Name:** IDACCS-run1_reranking 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `38bc95c1ea6684abd0cd1cf4e754f452` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-run1_rrank_rus 
[**`Results`**](./results.md#idaccs-run1_rrank_rus), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run1_rrank_rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run1_rrank_rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run1_rrank_rus.pdf) 

- :material-rename: **Name:** IDACCS-run1_rrank_rus 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `394805a1bd190c1b812ebf578f14072d` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-run1_rrank_zho 
[**`Results`**](./results.md#idaccs-run1_rrank_zho), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run1_rrank_zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run1_rrank_zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run1_rrank_zho.pdf) 

- :material-rename: **Name:** IDACCS-run1_rrank_zho 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `42ee18bce62f21d56f408c6e34ce3d55` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-run1_rus 
[**`Results`**](./results.md#idaccs-run1_rus), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run1_rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run1_rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run1_rus.pdf) 

- :material-rename: **Name:** IDACCS-run1_rus 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `c740241c5b9395b826963a036cc0bdb4` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-run1_zho 
[**`Results`**](./results.md#idaccs-run1_zho), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run1_zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run1_zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run1_zho.pdf) 

- :material-rename: **Name:** IDACCS-run1_zho 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `07185af85ed24aaefd9ddaad309c58ec` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; normalized 

---
#### IDACCS-run2_fas 
[**`Results`**](./results.md#idaccs-run2_fas), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run2_fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run2_fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run2_fas.pdf) 

- :material-rename: **Name:** IDACCS-run2_fas 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `857052b92079d24e351c92ce33711173` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; 

---
#### IDACCS-run2_rrank_fas 
[**`Results`**](./results.md#idaccs-run2_rrank_fas), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run2_rrank_fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run2_rrank_fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run2_rrank_fas.pdf) 

- :material-rename: **Name:** IDACCS-run2_rrank_fas 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `9007c7cfde1993724382484d424ec22d` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; 

---
#### IDACCS-run2_rrank_rus 
[**`Results`**](./results.md#idaccs-run2_rrank_rus), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run2_rrank_rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run2_rrank_rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run2_rrank_rus.pdf) 

- :material-rename: **Name:** IDACCS-run2_rrank_rus 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `29b7109d604a3d937b455f20e86d9ae0` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; 

---
#### IDACCS-run2_rrank_zho 
[**`Results`**](./results.md#idaccs-run2_rrank_zho), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run2_rrank_zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run2_rrank_zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run2_rrank_zho.pdf) 

- :material-rename: **Name:** IDACCS-run2_rrank_zho 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `a07355017e459ecdbdc1fb97a407cab4` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; 

---
#### IDACCS-run2_rus 
[**`Results`**](./results.md#idaccs-run2_rus), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run2_rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run2_rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run2_rus.pdf) 

- :material-rename: **Name:** IDACCS-run2_rus 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `1bf7b9faf30c1741a6b7a5af69ac4a41` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; 

---
#### IDACCS-run2_zho 
[**`Results`**](./results.md#idaccs-run2_zho), [**`Participants`**](./participants.md#idaccs), [**`Proceedings`**](./proceedings.md#extremely-fast-fine-tuning-for-cross-language-information-retrieval-via-generalized-canonical-correlation), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.IDACCS-run2_zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.IDACCS-run2_zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/IDACCS-run2_zho.pdf) 

- :material-rename: **Name:** IDACCS-run2_zho 
- :fontawesome-solid-user-group: **Participant:** IDACCS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `691c6cf2620684dbbe5cfce7a427879d` 
- :material-text: **Run description:** mvlearn finetuned LaBSE model trained on msmarco; 

---
#### jhumc.fa4.td.rf 
[**`Results`**](./results.md#jhumcfa4tdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.fa4.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.fa4.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.fa4.td.rf.pdf) 

- :material-rename: **Name:** jhumc.fa4.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `00171e049dd736bd693c28abbb4b54d7` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 4-grams. Relevance feedback. 

---
#### jhumc.fa5.td.ce.rf 
[**`Results`**](./results.md#jhumcfa5tdcerf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.fa5.td.ce.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.fa5.td.ce.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.fa5.td.ce.rf.pdf) 

- :material-rename: **Name:** jhumc.fa5.td.ce.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/29/2022 
- :fontawesome-solid-user-gear: **Type:** manual 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `439d7648abd902fdebd374b9b823226b` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 5-grams. Relevance feedback with Collection Enrichment.  

---
#### jhumc.fa5.td.rf 
[**`Results`**](./results.md#jhumcfa5tdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.fa5.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.fa5.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.fa5.td.rf.pdf) 

- :material-rename: **Name:** jhumc.fa5.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `4d161cc2ec52b5517f5fc7ddd78a43a6` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 5-grams. Relevance feedback. 

---
#### jhumc.fawords.td.rf 
[**`Results`**](./results.md#jhumcfawordstdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.fawords.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.fawords.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.fawords.td.rf.pdf) 

- :material-rename: **Name:** jhumc.fawords.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `7d705dccfc7f9022bf3e4f5711ffbe41` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Words. Relevance feedback. 

---
#### jhumc.ru4.td.rf 
[**`Results`**](./results.md#jhumcru4tdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.ru4.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.ru4.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.ru4.td.rf.pdf) 

- :material-rename: **Name:** jhumc.ru4.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `39933ea7d44d62148bde8223b83b3f4e` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 4-grams. Relevance feedback. 

---
#### jhumc.ru5.td.ce.rf 
[**`Results`**](./results.md#jhumcru5tdcerf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.ru5.td.ce.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.ru5.td.ce.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.ru5.td.ce.rf.pdf) 

- :material-rename: **Name:** jhumc.ru5.td.ce.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `cb8e9b1718cba74a23a2be787161198e` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 5-grams. Relevance feedback with Collection Enrichment. 

---
#### jhumc.ru5.td.rf 
[**`Results`**](./results.md#jhumcru5tdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.ru5.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.ru5.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.ru5.td.rf.pdf) 

- :material-rename: **Name:** jhumc.ru5.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `ee0a79e4a5be0f6c1ac3a9ea0d2ec2b0` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 5-grams. Relevance feedback. 

---
#### jhumc.ruwords.td.rf 
[**`Results`**](./results.md#jhumcruwordstdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.ruwords.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.ruwords.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.ruwords.td.rf.pdf) 

- :material-rename: **Name:** jhumc.ruwords.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `657c69f017c4e69a67a7ca2bcbc5d6fa` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Words. Relevance feedback. 

---
#### jhumc.zh4.td.rf 
[**`Results`**](./results.md#jhumczh4tdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.zh4.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.zh4.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.zh4.td.rf.pdf) 

- :material-rename: **Name:** jhumc.zh4.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `c3e870a9ffab82f409d149015da847c7` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 4-grams. Relevance feedback. 

---
#### jhumc.zh5.td.ce.rf 
[**`Results`**](./results.md#jhumczh5tdcerf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.zh5.td.ce.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.zh5.td.ce.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.zh5.td.ce.rf.pdf) 

- :material-rename: **Name:** jhumc.zh5.td.ce.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `8c592b08f2e5ba467c71daa9f2173112` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 5-grams. Relevance feedback with Collection Enrichment. 

---
#### jhumc.zh5.td.rf 
[**`Results`**](./results.md#jhumczh5tdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.zh5.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.zh5.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.zh5.td.rf.pdf) 

- :material-rename: **Name:** jhumc.zh5.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `e8aae0f218d6c6fdad604cd9bb334bc4` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Character 5-grams. Relevance feedback. 

---
#### jhumc.zhwords.td.rf 
[**`Results`**](./results.md#jhumczhwordstdrf), [**`Participants`**](./participants.md#jhumcnamee), [**`Proceedings`**](./proceedings.md#non-neural-baselines-experiments-for-clir-at-trec-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.jhumc.zhwords.td.rf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.jhumc.zhwords.td.rf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/jhumc.zhwords.td.rf.pdf) 

- :material-rename: **Name:** jhumc.zhwords.td.rf 
- :fontawesome-solid-user-group: **Participant:** jhu.mcnamee 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `7fea921004b94f10f02504841adc4ac0` 
- :material-text: **Run description:** Document Translation. Non-neural, language model IR. Words. Relevance feedback. 

---
#### KASYS-run 
[**`Results`**](./results.md#kasys-run), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS-run.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS-run.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS-run.pdf) 

- :material-rename: **Name:** KASYS-run 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `65e814ffc01ba9a3ed9f21c1345a27d7` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on English MS MARCO passgage We tried to reproduce ColBERT-X on test collection. 

---
#### KASYS-run-rus 
[**`Results`**](./results.md#kasys-run-rus), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS-run-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS-run-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS-run-rus.pdf) 

- :material-rename: **Name:** KASYS-run-rus 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `099a893c6d5f3ff777c2c1d94ca2f0f5` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on English MS MARCO passgage We tried to reproduce ColBERT-X on test collection. 

---
#### KASYS-run-zho 
[**`Results`**](./results.md#kasys-run-zho), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS-run-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS-run-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS-run-zho.pdf) 

- :material-rename: **Name:** KASYS-run-zho 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/25/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `e45c950f11177a49c14b41afccfc4995` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on English MS MARCO passgage We tried to reproduce ColBERT-X on test collection. 

---
#### KASYS_one_model-fas 
[**`Results`**](./results.md#kasys_one_model-fas), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS_one_model-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS_one_model-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS_one_model-fas.pdf) 

- :material-rename: **Name:** KASYS_one_model-fas 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `825c1a0baea0e9fb91ca6fd8a8aea3d7` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on neuMARCO three languages and English MS MARCO We add a language tag to each query. 

---
#### KASYS_one_model-rus 
[**`Results`**](./results.md#kasys_one_model-rus), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS_one_model-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS_one_model-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS_one_model-rus.pdf) 

- :material-rename: **Name:** KASYS_one_model-rus 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `29d5f9551fa6e1b83baf87e6bbf5067a` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on neuMARCO three languages and English MS MARCO We add a language tag to each query. 

---
#### KASYS_one_model-zho 
[**`Results`**](./results.md#kasys_one_model-zho), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS_one_model-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS_one_model-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS_one_model-zho.pdf) 

- :material-rename: **Name:** KASYS_one_model-zho 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `066708404b421d095f94cc44378e88e2` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on neuMARCO three languages and English MS MARCO We add a language tag to each query. 

---
#### KASYS_onemodel-rerank-fas 
[**`Results`**](./results.md#kasys_onemodel-rerank-fas), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS_onemodel-rerank-fas.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS_onemodel-rerank-fas.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS_onemodel-rerank-fas.pdf) 

- :material-rename: **Name:** KASYS_onemodel-rerank-fas 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `987df17cf3346bf61dbd5fce502b5f4d` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on neuMARCO three languages and English MS MARCO We add a language tag to each query. re-ranked the baselines provided by the track coordinators 

---
#### KASYS_onemodel-rerank-rus 
[**`Results`**](./results.md#kasys_onemodel-rerank-rus), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS_onemodel-rerank-rus.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS_onemodel-rerank-rus.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS_onemodel-rerank-rus.pdf) 

- :material-rename: **Name:** KASYS_onemodel-rerank-rus 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `6f83f709cd6f6359061ba333ebf06813` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on neuMARCO three languages and English MS MARCO We add a language tag to each query. re-ranked the baselines provided by the track coordinators 

---
#### KASYS_onemodel-rerank-zho 
[**`Results`**](./results.md#kasys_onemodel-rerank-zho), [**`Participants`**](./participants.md#kasys), [**`Proceedings`**](./proceedings.md#kasys-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.KASYS_onemodel-rerank-zho.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.KASYS_onemodel-rerank-zho.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/KASYS_onemodel-rerank-zho.pdf) 

- :material-rename: **Name:** KASYS_onemodel-rerank-zho 
- :fontawesome-solid-user-group: **Participant:** KASYS 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `2f03488068a0985965e559939a58da43` 
- :material-text: **Run description:** dense neural using XLM-RoBERTa and FAISS trained on neuMARCO three languages and English MS MARCO We add a language tag to each query. reranked the baselines provided by the track coordinators 

---
#### NLE_fa_adhoc 
[**`Results`**](./results.md#nle_fa_adhoc), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_fa_adhoc.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_fa_adhoc.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_fa_adhoc.pdf) 

- :material-rename: **Name:** NLE_fa_adhoc 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `f94ce8674a7f3fe88597f3920d38b277` 
- :material-text: **Run description:** Hybrid model without reranking. Ensemble of BM25 (sparse lexical)+SPLADE (sparse neural)+ColBERT (dense neural multirepresentation) 

---
#### NLE_fa_adhoc_rr 
[**`Results`**](./results.md#nle_fa_adhoc_rr), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_fa_adhoc_rr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_fa_adhoc_rr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_fa_adhoc_rr.pdf) 

- :material-rename: **Name:** NLE_fa_adhoc_rr 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `3823fbbb940808571f2beca249b18389` 
- :material-text: **Run description:** Hybrid model with reranking. 1st stage: Ensemble of BM25 (sparse lexical)+ SPLADE mt queries (sparse neural) + SPLADE mt docs (sparse neural)+ColBERT (dense neural multirepresentation) 2nd stage: Ensemble of castorini/monoT5-3b on english queries and mt docs (one reranking the ensemble and the other just reranking SPLADE mt docs) 

---
#### NLE_fa_mono 
[**`Results`**](./results.md#nle_fa_mono), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_fa_mono.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_fa_mono.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_fa_mono.pdf) 

- :material-rename: **Name:** NLE_fa_mono 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `70b09dc8065cec976cc0edc87eed9dd1` 
- :material-text: **Run description:** Hybrid model without reranking. Ensemble of BM25 (sparse lexical)+SPLADE (sparse neural)+ColBERT (dense neural multirepresentation) 

---
#### NLE_fa_mono_rr 
[**`Results`**](./results.md#nle_fa_mono_rr), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_fa_mono_rr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_fa_mono_rr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_fa_mono_rr.pdf) 

- :material-rename: **Name:** NLE_fa_mono_rr 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `46450de7a654c28317913ed6b98e1216` 
- :material-text: **Run description:** Hybrid model.  1st stage ensemble of BM25 (sparse lexical)+SPLADE (sparse neural)+ColBERT (dense neural multirepresentation) + 2nd stage reranking with XLMINFO and XLM-Roberta, Finally ensemble of SPLADE+COLBERT+XLMINFO+XLM-Roberta 

---
#### NLE_ru_adhoc 
[**`Results`**](./results.md#nle_ru_adhoc), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_ru_adhoc.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_ru_adhoc.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_ru_adhoc.pdf) 

- :material-rename: **Name:** NLE_ru_adhoc 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `131241c1d943bd2f10236af01c255d44` 
- :material-text: **Run description:** Hybrid model without reranking.  1st stage: A Ensemble of BM25 (sparse lexical)+ SPLADE mt queries (sparse neural) + ColBERT (dense neural multirepresentation) 

---
#### NLE_ru_adhoc_rr 
[**`Results`**](./results.md#nle_ru_adhoc_rr), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_ru_adhoc_rr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_ru_adhoc_rr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_ru_adhoc_rr.pdf) 

- :material-rename: **Name:** NLE_ru_adhoc_rr 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `323d4eb8c4f4c42fa770fdbfb47c3f4a` 
- :material-text: **Run description:** Hybrid model with reranking.  1st stage: A Ensemble of BM25 (sparse lexical)+ SPLADE mt queries (sparse neural) + SPLADE mt docs (sparse neural)+ColBERT (dense neural multirepresentation)  2nd stage: Castorini/monoT5-3b reranking on english queries and mt docs (one reranking the ensemble and the other just reranking SPLADE mt docs) Final: Ensemble of all models 

---
#### NLE_ru_mono 
[**`Results`**](./results.md#nle_ru_mono), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_ru_mono.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_ru_mono.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_ru_mono.pdf) 

- :material-rename: **Name:** NLE_ru_mono 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `2394419ca8d8c9cc31f4b3951dedeb91` 
- :material-text: **Run description:** Hybrid model.  1st stage ensemble of BM25 (sparse lexical)+SPLADE (sparse neural)+ColBERT (dense neural multi representation) + 2nd stage reranking with XLMINFO and XLM-Roberta. 

---
#### NLE_ru_mono_rr 
[**`Results`**](./results.md#nle_ru_mono_rr), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.NLE_ru_mono_rr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.NLE_ru_mono_rr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/NLE_ru_mono_rr.pdf) 

- :material-rename: **Name:** NLE_ru_mono_rr 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `d529af1357d69ea6fed38db75e5d6f41` 
- :material-text: **Run description:** Hybrid model with reranking.  1st stage ensemble of BM25 (sparse lexical)+SPLADE (sparse neural)+ColBERT (dense neural multi representation) + 2nd stage reranking with XLMINFO and XLM-Roberta, Finally ensemble of SPLADE+COLBERT+XLMINFO+XLM-Roberta 

---
#### p1.fa.hoc 
[**`Results`**](./results.md#p1fahoc), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p1.fa.hoc.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p1.fa.hoc.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p1.fa.hoc.pdf) 

- :material-rename: **Name:** p1.fa.hoc 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `f11174d3010d52671e9aebf3173d1a80` 
- :material-text: **Run description:** SPLADE on farsi queries translated by bing + mT5 reranker on bing description only 

---
#### p1.ru.hoc 
[**`Results`**](./results.md#p1ruhoc), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p1.ru.hoc.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p1.ru.hoc.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p1.ru.hoc.pdf) 

- :material-rename: **Name:** p1.ru.hoc 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `73da26eaf39a83bbe272ace02a3b09e9` 
- :material-text: **Run description:** SPLADE on russian queries translated by bing + mT5 reranker on bing description only 

---
#### p1.zh.hoc 
[**`Results`**](./results.md#p1zhhoc), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p1.zh.hoc.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p1.zh.hoc.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p1.zh.hoc.pdf) 

- :material-rename: **Name:** p1.zh.hoc 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `044a2e130404f0f441902759f7ab6b77` 
- :material-text: **Run description:** Anserini BM25 RRF with different 4 translations (not tainted with human translation) + mT5 reranker on English description and title 

---
#### p2.fa.rerank 
[**`Results`**](./results.md#p2farerank), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p2.fa.rerank.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p2.fa.rerank.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p2.fa.rerank.pdf) 

- :material-rename: **Name:** p2.fa.rerank 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `e0f855df4af22ba9647a1dfc5e6b07bd` 
- :material-text: **Run description:** mT5 reranker on bing description only 

---
#### p2.ru.rerank 
[**`Results`**](./results.md#p2rurerank), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p2.ru.rerank.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p2.ru.rerank.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p2.ru.rerank.pdf) 

- :material-rename: **Name:** p2.ru.rerank 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `21f5e72c4c8b1d7ff4c92ca2af719e50` 
- :material-text: **Run description:** mT5 reranker on bing description only 

---
#### p2.zh.rerank 
[**`Results`**](./results.md#p2zhrerank), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p2.zh.rerank.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p2.zh.rerank.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p2.zh.rerank.pdf) 

- :material-rename: **Name:** p2.zh.rerank 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `3ac173f74d789282c31aa7feb2a95d56` 
- :material-text: **Run description:** mT5 reranker on English description and title 

---
#### p3.fa.mono 
[**`Results`**](./results.md#p3famono), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p3.fa.mono.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p3.fa.mono.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p3.fa.mono.pdf) 

- :material-rename: **Name:** p3.fa.mono 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `17c800467172aff0f2b7393d254892a6` 
- :material-text: **Run description:** SPLADE on farsi queries + mT5 reranker on description only 

---
#### p3.ru.mono 
[**`Results`**](./results.md#p3rumono), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p3.ru.mono.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p3.ru.mono.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p3.ru.mono.pdf) 

- :material-rename: **Name:** p3.ru.mono 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `2a67dc17c73569ccb9cee81777a7822e` 
- :material-text: **Run description:** SPLADE on russian queries + mT5 reranker on description only 

---
#### p3.zh.mono 
[**`Results`**](./results.md#p3zhmono), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p3.zh.mono.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p3.zh.mono.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p3.zh.mono.pdf) 

- :material-rename: **Name:** p3.zh.mono 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `2e9c46ec15ff6a15462f85eaab46f4d1` 
- :material-text: **Run description:** Anserini BM25 RRF with different 2 translations (tainted with human translation) + mT5 reranker on human translation description and title 

---
#### p4.fa.hoc 
[**`Results`**](./results.md#p4fahoc), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p4.fa.hoc.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p4.fa.hoc.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p4.fa.hoc.pdf) 

- :material-rename: **Name:** p4.fa.hoc 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `710a1e1abf8d6dfe86bc4579ccd5471a` 
- :material-text: **Run description:** Anserini BM25 RRF with different 3 translations (not tainted with human translation) + mT5 reranker on Bing translation on description 

---
#### p4.ru.hoc 
[**`Results`**](./results.md#p4ruhoc), [**`Participants`**](./participants.md#nmunicamp), [**`Proceedings`**](./proceedings.md#neuralmind-unicamp-at-2022-trec-neuclir-large-boring-rerankers-for-cross-lingual-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.p4.ru.hoc.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.p4.ru.hoc.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/p4.ru.hoc.pdf) 

- :material-rename: **Name:** p4.ru.hoc 
- :fontawesome-solid-user-group: **Participant:** NM.unicamp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `f525e1458dde2a732781b09c3edec12e` 
- :material-text: **Run description:** Anserini BM25 RRF with different 2 translations (not tainted with human translation) + mT5 reranker on Bing translation on description 

---
#### RietRandomRun 
[**`Results`**](./results.md#rietrandomrun), [**`Participants`**](./participants.md#riet), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.RietRandomRun.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.RietRandomRun.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/RietRandomRun.pdf) 

- :material-rename: **Name:** RietRandomRun 
- :fontawesome-solid-user-group: **Participant:** RIET 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `f187102c6f2ac6bc8cafdc52e25393a4` 
- :material-text: **Run description:** Random run 

---
#### RietRandomRun2 
[**`Results`**](./results.md#rietrandomrun2), [**`Participants`**](./participants.md#riet), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.RietRandomRun2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.RietRandomRun2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/RietRandomRun2.pdf) 

- :material-rename: **Name:** RietRandomRun2 
- :fontawesome-solid-user-group: **Participant:** RIET 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `b2e234073286c3cf8c45e186ba966cf8` 
- :material-text: **Run description:** Random Run 

---
#### RietRandomRun3 
[**`Results`**](./results.md#rietrandomrun3), [**`Participants`**](./participants.md#riet), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.RietRandomRun3.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.RietRandomRun3.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/RietRandomRun3.pdf) 

- :material-rename: **Name:** RietRandomRun3 
- :fontawesome-solid-user-group: **Participant:** RIET 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `4b9e5e991806d479e1111b1a6217a258` 
- :material-text: **Run description:** Random run 

---
#### ru_2rrf 
[**`Results`**](./results.md#ru_2rrf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_2rrf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_2rrf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_2rrf.pdf) 

- :material-rename: **Name:** ru_2rrf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `138db94e76dbd2883080253e97c36023` 
- :material-text: **Run description:** Sparse BM25 

---
#### ru_2rrf2 
[**`Results`**](./results.md#ru_2rrf2), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_2rrf2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_2rrf2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_2rrf2.pdf) 

- :material-rename: **Name:** ru_2rrf2 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `12c4ff635d5ff33d2ae72e55a308129f` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### ru_2rrfprf 
[**`Results`**](./results.md#ru_2rrfprf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_2rrfprf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_2rrfprf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_2rrfprf.pdf) 

- :material-rename: **Name:** ru_2rrfprf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `f50cf57ef6bfd749160ffc65b3921b68` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### ru_2t 
[**`Results`**](./results.md#ru_2t), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_2t.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_2t.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_2t.pdf) 

- :material-rename: **Name:** ru_2t 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `39945e178f8c1ccd49445a6fd1cce53c` 
- :material-text: **Run description:** Sparse BM25 

---
#### ru_2tr 
[**`Results`**](./results.md#ru_2tr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_2tr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_2tr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_2tr.pdf) 

- :material-rename: **Name:** ru_2tr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `4a04af59814f83b057678ea48fae7ae9` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### ru_dense-rrf.BM25.SPLADE 
[**`Results`**](./results.md#ru_dense-rrfbm25splade), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_dense-rrf.BM25.SPLADE.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_dense-rrf.BM25.SPLADE.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_dense-rrf.BM25.SPLADE.pdf) 

- :material-rename: **Name:** ru_dense-rrf.BM25.SPLADE 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `ecf2b91e1835c3fbc23c5faa5d1f5a8d` 
- :material-text: **Run description:**     For Fa:          We RRF the runfiles of tags: dense-rrf.prf, BM25 Baseline run fa_3rrfprf and SPLADE run rocchio.fa.official_ht.dt, keeping the top1k.     For Ru:         We RRF the runfiles of tags: dense-rrf.prf, BM25 Baseline run ru_2rrfprf and SPLADE run rocchio.ru.official_ht.dt, keeping the top1k.     For Zh:         We RRF the runfiles of tags: dense-rrf.prf and BM25 Baseline run zh_4rrfprf, keeping the top1k. 

---
#### ru_dense-rrf.prf 
[**`Results`**](./results.md#ru_dense-rrfprf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_dense-rrf.prf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_dense-rrf.prf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_dense-rrf.prf.pdf) 

- :material-rename: **Name:** ru_dense-rrf.prf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `258f4a450aef59391fd891246a4db649` 
- :material-text: **Run description:**     We RRF the runfiles of tags: xdpr.msmarco.official_ht.d.prf, xdpr.xor-hn-mmarco.EN-q.d.prf, xdpr.msmarco.2rrf-mt-q.all.prf and keep the top1k. 

---
#### ru_dt 
[**`Results`**](./results.md#ru_dt), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_dt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_dt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_dt.pdf) 

- :material-rename: **Name:** ru_dt 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `930e4353c3baa5c5ed4b6757334fb3e7` 
- :material-text: **Run description:** Sparse BM25 

---
#### ru_dtr 
[**`Results`**](./results.md#ru_dtr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_dtr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_dtr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_dtr.pdf) 

- :material-rename: **Name:** ru_dtr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `6547590df85fbd87f784aeba0f77ff39` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### ru_qt 
[**`Results`**](./results.md#ru_qt), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_qt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_qt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_qt.pdf) 

- :material-rename: **Name:** ru_qt 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `01d5f44020932fe4c7863305f4247749` 
- :material-text: **Run description:** Sparse BM25 

---
#### ru_qtr 
[**`Results`**](./results.md#ru_qtr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_qtr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_qtr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_qtr.pdf) 

- :material-rename: **Name:** ru_qtr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `c84759a61f6c811264886e956a415286` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### ru_xdpr.mm.2rrf-mtQ.all.R 
[**`Results`**](./results.md#ru_xdprmm2rrf-mtqallr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_xdpr.mm.2rrf-mtQ.all.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_xdpr.mm.2rrf-mtQ.all.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_xdpr.mm.2rrf-mtQ.all.R.pdf) 

- :material-rename: **Name:** ru_xdpr.mm.2rrf-mtQ.all.R 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `1e8e95e11ce5fd5cb2da7a5138bf5f1c` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R and fine-tuned on MS MARCO dataset for 40 epoch.     The model then is applied on the NeuCLIR dataset in a zero-shot mannar. No sparse model is involved.     In the inference we obtain {2,4} different runfiles using different version of translated queries, then RRF all runfiles and keep the top1k.     We used Rocchio provided by Pyserini (config:  --prf-depth 5 --rocchio-topk 5  --rocchio-alpha 0.4  --rocchio-beta 0.6)  

---
#### ru_xdpr.ms.oht.d.R 
[**`Results`**](./results.md#ru_xdprmsohtdr), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_xdpr.ms.oht.d.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_xdpr.ms.oht.d.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_xdpr.ms.oht.d.R.pdf) 

- :material-rename: **Name:** ru_xdpr.ms.oht.d.R 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `d08fffdd60114f4c27c884cf4b174445` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R and fine-tuned on MS MARCO dataset for 40 epoch.     The model then is applied on the NeuCLIR dataset in a zero-shot mannar. No sparse model is involved.     We used Rocchio provided by Pyserini (config:  --prf-depth 5 --rocchio-topk 5  --rocchio-alpha 0.4  --rocchio-beta 0.6)  

---
#### ru_xdpr.xorHn-mm.EN.d.R 
[**`Results`**](./results.md#ru_xdprxorhn-mmendr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.ru_xdpr.xorHn-mm.EN.d.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.ru_xdpr.xorHn-mm.EN.d.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/ru_xdpr.xorHn-mm.EN.d.R.pdf) 

- :material-rename: **Name:** ru_xdpr.xorHn-mm.EN.d.R 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `104f8738924a3d3699e084bc7f1defa0` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R.     The model is firstly trained on XOR-TyDi data, involving all languages, then fine-tuned on mMARCO dataset.     We use the offical small training set of mMARCO, but we map the query id and document id into different languages, e.g., query in Chinese and Document in English.      Note that we use all the languages in mMARCO, so the query and document might involve languages that's not in target language or English (e.g. Arabic)     The model then is applied on the NeuCLIR dataset in a zero-shot mannar, where the relevance score is directly matched between English queries and target documents.     No sparse model is involved. 

---
#### splade_farsi_dt 
[**`Results`**](./results.md#splade_farsi_dt), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.splade_farsi_dt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.splade_farsi_dt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/splade_farsi_dt.pdf) 

- :material-rename: **Name:** splade_farsi_dt 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `de6a84702a09d1a43557dd339da02d95` 
- :material-text: **Run description:** Splade model (sparse neural) trained in english msmarco (available at: https://huggingface.co/naver/splade-cocondenser-selfdistil) 

---
#### splade_farsi_ht 
[**`Results`**](./results.md#splade_farsi_ht), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.splade_farsi_ht.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.splade_farsi_ht.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/splade_farsi_ht.pdf) 

- :material-rename: **Name:** splade_farsi_ht 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `52c67fc9ea1d5d6922ebbeb56b1eef94` 
- :material-text: **Run description:** Splade model with a "distilbert" sized transformer architecture which is first pretrained with farsi-neuMARCO documents and farsi-neuclir documents. The model is then MSMARCO with queries and documents translated to farsi using in-batch negatives 

---
#### splade_farsi_mt 
[**`Results`**](./results.md#splade_farsi_mt), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.splade_farsi_mt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.splade_farsi_mt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/splade_farsi_mt.pdf) 

- :material-rename: **Name:** splade_farsi_mt 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `5f9591c584999c65f27dde279c0e33b0` 
- :material-text: **Run description:** Splade model with a "distilbert" sized transformer architecture which is first pretrained with farsi-neuMARCO documents and farsi-neuclir documents. The model is then MSMARCO with queries and documents translated to farsi using in-batch negatives 

---
#### splade_russian_dt 
[**`Results`**](./results.md#splade_russian_dt), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.splade_russian_dt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.splade_russian_dt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/splade_russian_dt.pdf) 

- :material-rename: **Name:** splade_russian_dt 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `850b53bcd9e9af9403d0a5c707c2ee25` 
- :material-text: **Run description:** Splade model (sparse neural) trained in english msmarco (available at: https://huggingface.co/naver/splade-cocondenser-selfdistil) 

---
#### splade_russian_ht 
[**`Results`**](./results.md#splade_russian_ht), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.splade_russian_ht.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.splade_russian_ht.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/splade_russian_ht.pdf) 

- :material-rename: **Name:** splade_russian_ht 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `bcd70224777af06c9181e0a13e011964` 
- :material-text: **Run description:** Splade model (sparse neural) with a "distilbert" sized transformer architecture which is first pretrained with russian-MMARCO documents, russian-MrTyDi and russian-neuclir documents. The model is then finetuned MSMARCO with queries and documents translated to russian using in-batch negatives 

---
#### splade_russian_mt 
[**`Results`**](./results.md#splade_russian_mt), [**`Participants`**](./participants.md#nle), [**`Proceedings`**](./proceedings.md#naver-labs-europe-splade-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.splade_russian_mt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.splade_russian_mt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/splade_russian_mt.pdf) 

- :material-rename: **Name:** splade_russian_mt 
- :fontawesome-solid-user-group: **Participant:** NLE 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `3f8593212f61cad312ec541037f5bac3` 
- :material-text: **Run description:** Splade model (sparse neural) with a "distilbert" sized transformer architecture which is first pretrained with russian-MMARCO documents, russian-MrTyDi and russian-neuclir documents. The model is then finetuned MSMARCO with queries and documents translated to russian using in-batch negatives 

---
#### umcp_hmm_fa 
[**`Results`**](./results.md#umcp_hmm_fa), [**`Participants`**](./participants.md#umcp), [**`Proceedings`**](./proceedings.md#probabilistic-structured-queries-the-university-of-maryland-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.umcp_hmm_fa.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.umcp_hmm_fa.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/umcp_hmm_fa.pdf) 

- :material-rename: **Name:** umcp_hmm_fa 
- :fontawesome-solid-user-group: **Participant:** umcp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** fas 
- :material-fingerprint: **MD5:** `1dadab2fa31a7f21e35ee611ce45e92d` 
- :material-text: **Run description:** This run uses a Probabilistic Structured Query (PSQ) implemented using an HMM. 

---
#### umcp_hmm_ru 
[**`Results`**](./results.md#umcp_hmm_ru), [**`Participants`**](./participants.md#umcp), [**`Proceedings`**](./proceedings.md#probabilistic-structured-queries-the-university-of-maryland-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.umcp_hmm_ru.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.umcp_hmm_ru.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/umcp_hmm_ru.pdf) 

- :material-rename: **Name:** umcp_hmm_ru 
- :fontawesome-solid-user-group: **Participant:** umcp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** rus 
- :material-fingerprint: **MD5:** `ade46a47cea76d64682a0e0c00aa0e9f` 
- :material-text: **Run description:** This run uses a Probabilistic Structured Query (PSQ) implemented with an HMM. 

---
#### umcp_hmm_zh 
[**`Results`**](./results.md#umcp_hmm_zh), [**`Participants`**](./participants.md#umcp), [**`Proceedings`**](./proceedings.md#probabilistic-structured-queries-the-university-of-maryland-at-the-trec-2022-neuclir-track), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.umcp_hmm_zh.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.umcp_hmm_zh.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/umcp_hmm_zh.pdf) 

- :material-rename: **Name:** umcp_hmm_zh 
- :fontawesome-solid-user-group: **Participant:** umcp 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `4a9f1eb79d282ac33d14340a189bbe80` 
- :material-text: **Run description:** This run uses Probabilistic Structured Query (PSQ) implemented using an HMM model. 

---
#### zh_2t 
[**`Results`**](./results.md#zh_2t), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_2t.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_2t.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_2t.pdf) 

- :material-rename: **Name:** zh_2t 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `53e6517556b0332f17c7c6d2899f7017` 
- :material-text: **Run description:** Sparse BM25 retrieval. Fusion of English queries retrieval on Translated Documents and Human translated queries on provided documents. 

---
#### zh_2tr 
[**`Results`**](./results.md#zh_2tr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_2tr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_2tr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_2tr.pdf) 

- :material-rename: **Name:** zh_2tr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `3a8c1fc3a49d8b1d83031073e85ca505` 
- :material-text: **Run description:** Sparse BM25 retrieval + Rocchio Pseudo Relevance Feedback. Fusion of English queries retrieval on Translated Documents and Human translated queries on provided documents. 

---
#### zh_4rrf 
[**`Results`**](./results.md#zh_4rrf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_4rrf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_4rrf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_4rrf.pdf) 

- :material-rename: **Name:** zh_4rrf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `71db7ff7920df4b489cb6ebfa9dabc1d` 
- :material-text: **Run description:** Sparse BM25 Reciprocal Rank Fusion of {Caiyun, Youdao, bing, Huawei} translated queries x {title, desc+title} (BM25) 

---
#### zh_4rrf2 
[**`Results`**](./results.md#zh_4rrf2), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_4rrf2.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_4rrf2.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_4rrf2.pdf) 

- :material-rename: **Name:** zh_4rrf2 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `9a337720f475f0b1f348f707daf652d2` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) 

---
#### zh_4rrfprf 
[**`Results`**](./results.md#zh_4rrfprf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_4rrfprf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_4rrfprf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_4rrfprf.pdf) 

- :material-rename: **Name:** zh_4rrfprf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `ca75f4799c0fe6959d61eae2c74dc696` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) Recciprocal Rank Fusion of {Caiyun, Youdao, bing, Huawei, Human translations of topics} x {title, desc+title} (BM25+Rocchio)  

---
#### zh_dense-rrf.BM25 
[**`Results`**](./results.md#zh_dense-rrfbm25), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_dense-rrf.BM25.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_dense-rrf.BM25.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_dense-rrf.BM25.pdf) 

- :material-rename: **Name:** zh_dense-rrf.BM25 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `c8c7857bb0c1e03e371cfed9033e7520` 
- :material-text: **Run description:**     For Fa:          We RRF the runfiles of tags: dense-rrf.prf, BM25 Baseline run fa_3rrfprf and SPLADE run rocchio.fa.official_ht.dt, keeping the top1k.     For Ru:         We RRF the runfiles of tags: dense-rrf.prf, BM25 Baseline run ru_2rrfprf and SPLADE run rocchio.ru.official_ht.dt, keeping the top1k.     For Zh:         We RRF the runfiles of tags: dense-rrf.prf and BM25 Baseline run zh_4rrfprf, keeping the top1k. 

---
#### zh_dense-rrf.prf 
[**`Results`**](./results.md#zh_dense-rrfprf), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_dense-rrf.prf.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_dense-rrf.prf.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_dense-rrf.prf.pdf) 

- :material-rename: **Name:** zh_dense-rrf.prf 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `411b75723e66af72c5da63386630748f` 
- :material-text: **Run description:**     We RRF the runfiles of tags: xdpr.msmarco.official_ht.d.prf, xdpr.xor-hn-mmarco.EN-q.d.prf, xdpr.msmarco.2rrf-mt-q.all.prf and keep the top1k. 

---
#### zh_dt 
[**`Results`**](./results.md#zh_dt), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_dt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_dt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_dt.pdf) 

- :material-rename: **Name:** zh_dt 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `02c6c40b4fdf5ee932459a8c55923da1` 
- :material-text: **Run description:** Sparse BM25 doc translation (query: English, docs: Sockeye-translated Chinese), description+title 

---
#### zh_dtr 
[**`Results`**](./results.md#zh_dtr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_dtr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_dtr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_dtr.pdf) 

- :material-rename: **Name:** zh_dtr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `5384c142b4bc76b04faf9181e82ec875` 
- :material-text: **Run description:** Sparse BM25  + Rocchio (Pseudo Relevance Feedback) doc translation (query: English, docs: Sockeye-translated Chinese), description+title 

---
#### zh_qt 
[**`Results`**](./results.md#zh_qt), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_qt.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_qt.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_qt.pdf) 

- :material-rename: **Name:** zh_qt 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `5fa551693b321b66d077d140538f4ef1` 
- :material-text: **Run description:** Sparse BM25. query translation (query: human-translated Chinese, docs: Chinese), description+title topics 

---
#### zh_qtr 
[**`Results`**](./results.md#zh_qtr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_qtr.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_qtr.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_qtr.pdf) 

- :material-rename: **Name:** zh_qtr 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/26/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `231f07ac3bcc82b67f36ca24576d75e9` 
- :material-text: **Run description:** Sparse BM25 + Rocchio pseudo relevance feedback query translation (query: human-translated Chinese, docs: Chinese), description+title,  

---
#### zh_xdpr.mm.4rrf-mtQ.all.R 
[**`Results`**](./results.md#zh_xdprmm4rrf-mtqallr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_xdpr.mm.4rrf-mtQ.all.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_xdpr.mm.4rrf-mtQ.all.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_xdpr.mm.4rrf-mtQ.all.R.pdf) 

- :material-rename: **Name:** zh_xdpr.mm.4rrf-mtQ.all.R 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `6f0daad17462be1c66ff04054d2c7198` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R and fine-tuned on MS MARCO dataset for 40 epoch.     The model then is applied on the NeuCLIR dataset in a zero-shot mannar. No sparse model is involved.     In the inference we obtain {2,4} different runfiles using different version of translated queries, then RRF all runfiles and keep the top1k.     We used Rocchio provided by Pyserini (config:  --prf-depth 5 --rocchio-topk 5  --rocchio-alpha 0.4  --rocchio-beta 0.6)  

---
#### zh_xdpr.ms.oht.d.R 
[**`Results`**](./results.md#zh_xdprmsohtdr), [**`Participants`**](./participants.md#huaweimtl), [**`Proceedings`**](./proceedings.md#huawei-noah-s-ark-lab-at-trec-neuclir-2022), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_xdpr.ms.oht.d.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_xdpr.ms.oht.d.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_xdpr.ms.oht.d.R.pdf) 

- :material-rename: **Name:** zh_xdpr.ms.oht.d.R 
- :fontawesome-solid-user-group: **Participant:** huaweimtl 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `68e48b4badefe6771439c219b183c3c4` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R and fine-tuned on MS MARCO dataset for 40 epoch.     The model then is applied on the NeuCLIR dataset in a zero-shot mannar. No sparse model is involved.     We used Rocchio provided by Pyserini (config:  --prf-depth 5 --rocchio-topk 5  --rocchio-alpha 0.4  --rocchio-beta 0.6)  

---
#### zh_xdpr.xorHn-mm.EN.d.R 
[**`Results`**](./results.md#zh_xdprxorhn-mmendr), [**`Participants`**](./participants.md#h2oloo), [**`Proceedings`**](./proceedings.md#simple-yet-effective-neural-ranking-and-reranking-baselines-for-cross-lingual-information-retrieval), [**`Input`**](https://trec.nist.gov/results/trec31/neuclir/input.zh_xdpr.xorHn-mm.EN.d.R.gz), [**`Summary`**](https://trec.nist.gov/results/trec31/neuclir/summary.zh_xdpr.xorHn-mm.EN.d.R.trec_eval), [**`Appendix`**](https://trec.nist.gov/pubs/trec31/appendices/neuclir/zh_xdpr.xorHn-mm.EN.d.R.pdf) 

- :material-rename: **Name:** zh_xdpr.xorHn-mm.EN.d.R 
- :fontawesome-solid-user-group: **Participant:** h2oloo 
- :material-format-text: **Track:** NeuCLIR 
- :material-calendar: **Year:** 2022 
- :material-upload: **Submission:** 7/27/2022 
- :fontawesome-solid-user-gear: **Type:** auto 
- :material-text-search: **Task:** zho 
- :material-fingerprint: **MD5:** `e302fc3348305c84188b19d287f9e33e` 
- :material-text: **Run description:**     We use the dense retrieval model DPR, where the model is initialized with XLM-R.     The model is firstly trained on XOR-TyDi data, involving all languages, then fine-tuned on mMARCO dataset.     We use the offical small training set of mMARCO, but we map the query id and document id into different languages, e.g., query in Chinese and Document in English.      Note that we use all the languages in mMARCO, so the query and document might involve languages that's not in target language or English (e.g. Arabic)     The model then is applied on the NeuCLIR dataset in a zero-shot mannar, where the relevance score is directly matched between English queries and target documents.     No sparse model is involved. 

---
