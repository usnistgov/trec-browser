# Text REtrieval Conference (TREC) 1997 

## Adhoc

[`Overview`](./adhoc/overview.md), [`Proceedings`](./adhoc/proceedings.md), [`Data`](./adhoc/data.md), [`Results`](./adhoc/results.md), [`Runs`](./adhoc/runs.md), [`Participants`](./adhoc/participants.md)

{==

The ad hoc task investigates the performance of systems that search a static set of documents using new topics. This task is similar to how a researcher might use a library-the collection is known but the questions likely to be asked are not known.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- Ellen Voorhees (National Institute of Standards and Technology) 
- D. Harman (National Institute of Standards and Technology) 


:fontawesome-solid-globe: **Track Web Page:** [`https://trec.nist.gov/data/test_coll.html`](https://trec.nist.gov/data/test_coll.html) 

---

## Routing

[`Overview`](./routing/overview.md), [`Proceedings`](./routing/proceedings.md), [`Data`](./routing/data.md), [`Results`](./routing/results.md), [`Runs`](./routing/runs.md), [`Participants`](./routing/participants.md)

{==

The routing task in the TREC workshops investigates the performance of systems that use standing queries to search new streams of documents. These searches are similar to those required by news clipping services and library profiling systems. A true routing environment is simulated in TREC by using topics that have known relevant documents and testing on a completely new document set.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- E. Voorhees (National Institute of Standards and Technology) 
- D. Harman (National Institute of Standards and Technology) 




---

## Chinese

[`Overview`](./chinese/overview.md), [`Proceedings`](./chinese/proceedings.md), [`Data`](./chinese/data.md), [`Results`](./chinese/results.md), [`Runs`](./chinese/runs.md), [`Participants`](./chinese/participants.md)

{==

The TREC-6 conference was the fourth year in which document retrieval in a language other than English was carried out. In TREC-3, 4 groups participated in an ad hoc retrieval task on a collection of 208 Mbytes of Mexican newspaper text in the Spanish language. In TREC-4 there were 10 groups who participated, once again in an ad hoc document retrieval task on the same Mexican newspaper texts but with new topics. In TREC-5 there was a change of document corpus and new topics for the Spanish ad hoc retrieval task and a corpus of documents and topics to support ad hoc retrieval in the Chinese language was introduced for the first time. In TREC-6 there was two tracks in which languages other than English were explored. In the Chinese track, a second set of topics were evaluated against the existing corpus. In the cross-lingual track experiments were conducted where queries in one language were used against a document corpus in another language. This report concentrates solely on the Chinese track.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- R. Wilkinson (CSIRO) 




---

## Cross-Language

[`Overview`](./clir/overview.md), [`Proceedings`](./clir/proceedings.md), [`Data`](./clir/data.md), [`Results`](./clir/results.md), [`Runs`](./clir/runs.md), [`Participants`](./clir/participants.md)

{==

Cross-Language Information Retrieval (CLIR) was a new task in the TREC-6 evaluation. In contrast to the multilingual track included in previous TREC evaluations, which was concerned with information retrieval in Spanish or Chi-nese, the cross-language retrieval track focuses on the retrieval situation where the documents are written in a language which is different than the language used to specify the queries. The TREC-6 track used documents in English, French and German and queries in English, French, German, Spanish and Dutch.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- P. Schauble (Swiss Federal Institute of Technology (ETH)) 
- P. Sheridan (Swiss Federal Institute of Technology (ETH)) 




---

## Filtering

[`Overview`](./filtering/overview.md), [`Proceedings`](./filtering/proceedings.md), [`Data`](./filtering/data.md), [`Runs`](./filtering/runs.md), [`Participants`](./filtering/participants.md)

{==

Given a topic description and a large collection of documents, a sample of which have been evaluated as relevant or not relevant for that topic, construct a query profile and a routing function which will score and rank new documents according to their likelihood of relevance.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- D.A. Hull (Xerox Research Centre Europe) 




---

## High-Precision

[`Overview`](./hp/overview.md), [`Proceedings`](./hp/proceedings.md), [`Results`](./hp/results.md), [`Runs`](./hp/runs.md), [`Participants`](./hp/participants.md)

{==

The High-Precision Track is a new track for TREC. It has a very simple short description: for each query, a user should find the best 10 documents possible within 5 minutes clock time. One realistic scenario corresponding to this task might be that your boss asks you for a quick report on some area and you need to find some information on the area fast.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- C. Buckley (SabIR Research Inc.) 




---

## Interactive

[`Overview`](./interactive/overview.md), [`Proceedings`](./interactive/proceedings.md), [`Data`](./interactive/data.md), [`Runs`](./interactive/runs.md), [`Participants`](./interactive/participants.md)

{==

The high-level goal of the TREC-6 Interactive Track was the investigation of searching as an interactive information retrieval (IR) task by examining the process as well as the outcome. To these ends the track specification provided for two levels of experimenta-tion.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- P. Over (National Institute of Standards and Technology) 


:fontawesome-solid-globe: **Track Web Page:** [`https://trec.nist.gov/data/t6i/t6i.html`](https://trec.nist.gov/data/t6i/t6i.html) 

---

## NLP

[`Overview`](./nlp/overview.md), [`Proceedings`](./nlp/proceedings.md), [`Results`](./nlp/results.md), [`Runs`](./nlp/runs.md), [`Participants`](./nlp/participants.md)

{==

The NLP track was initiated to explore whether the natural language processing (NLP) techniques available today are mature enough to have an impact on IR, and specifically whether they can offer an advantage over purely quantitative retrieval methods. The track used the 50 ad hoc topics and the Financial Times document set.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- Ellen Voorhees (National Institute of Standards and Technology) 
- D. Harman (National Institute of Standards and Technology) 




---

## Spoken Document Retrieval

[`Overview`](./sdr/overview.md), [`Proceedings`](./sdr/proceedings.md), [`Data`](./sdr/data.md), [`Runs`](./sdr/runs.md), [`Participants`](./sdr/participants.md)

{==

Spoken Document Retrieval (SDR) involves the retrieval of excerpts from recordings of speech using a combination of automatic speech recognition and information retrieval techniques. In performing SDR, a speech recognition engine is applied to an audio input stream and generates a time-marked textual representation (transcription) of the speech. The transcription is then indexed and may be searched using an Information Retrieval engine.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- J. Garofolo (National Institute of Standards and Technology) 
- E. Voorhees (National Institute of Standards and Technology) 
- V. Stanford (National Institute of Standards and Technology) 
- K. Sparck Jones (Cambridge University) 




---

## Very Large Corpus

[`Overview`](./vlc/overview.md), [`Proceedings`](./vlc/proceedings.md), [`Runs`](./vlc/runs.md), [`Participants`](./vlc/participants.md)

{==

The emergence of real world applications for text collections orders of magnitude larger than the TREC collection has motivated the introduction of a Very Large Collection track within the TREC framework. The 20 gigabyte data set developed for the track is char-acterised, track objectives and guidelines are summarised and the measures employed are described. The contribution of the organizations which made data available is gratefully acknowledged and an overview is given of the track participants, the methods used and the results obtained. Alternative options for the future of the track are discussed.

==}

:fontawesome-solid-user-group: **Track coordinators:**

- D. Hawking (Australian National University) 
- P. Thistlewaite (Australian National University) 




---

